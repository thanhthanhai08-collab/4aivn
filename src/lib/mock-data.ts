
import type { Tool, NewsArticle, AIModel } from '@/lib/types';

export const mockUser = {
  id: 'mock-user-123',
  email: 'user@example.com',
  displayName: 'Người dùng Demo',
  photoURL: 'https://placehold.co/100x100.png',
};

export const mockTools: Tool[] = [
  {
    id: 'gpt-image-1',
    name: 'GPT Image 1',
    context: 'Tạo hình ảnh',
    developer: 'OpenAI',
    ranking: 2,
    description: 'GPT Image 1 là mô hình tạo, chỉnh sửa hình ảnh do OpenAI phát triển nội bộ, chính thức được ra mắt vào tháng 5 năm 2024 được tích hợp sẵn vào model GPT-4o không giống như DALL·E là một model riêng, GPT Image 1 được xây dựng hoàn toàn mới, với mục tiêu tạo ra hình ảnh thực tế, logic và mạch lạc với văn bản đầu vào(prompt).\n+ Vì được tích hợp sâu với GPT 4o cho nên GPT Image 1 hoàn toàn có thể hiểu ngữ cảnh hội thoại đưa ra hình ảnh phù hợp với yêu cầu chi tiết. Hoặc mọi người có thể sử dụng tùy chỉnh GPT Image 1 thông qua API.\n+ Hỗ trợ tất cả các kiểu tạo hình ảnh đó là tạo hình ảnh từ hình ảnh, tạo hình ảnh từ mô tả, chỉnh sửa hình ảnh từ hình ảnh, chỉnh sửa hình ảnh từ mô tả\n+ Đặc biệt là có thể tạo nhân vật và hành động nhất quán với mô tả và một điểm cộng nữa là chữ trên hình ảnh tiếng Anh thì cực kì chính xác còn tiếng Việt thì độ chuẩn xác chỉ tầm 50%.\n+ Đến hiện tại thì GPT Image chỉ hỗ trợ 3 loại kích thước ảnh giống như ở phần chi phí. Còn về chi phí tạo ảnh là: \n• Chất lượng LOW thì ảnh 1024x1024 (0.011 USD/1 ảnh) ảnh 1024x1536 (0.016 USD/1 ảnh) ảnh 1536x1024 (0.016 USD/1 ảnh).\n• Chất lượng Medium thì ảnh 1024x1024 (0.042 USD/1 ảnh) ảnh 1024x1536 (0.063 USD/1 ảnh) ảnh 1536x1024 (0.063 USD/1 ảnh).\n• Chất lượng High thì ảnh 1024x1024 (0.167 USD/1 ảnh) ảnh 1024x1536 (0.25 USD/1 ảnh) ảnh 1536x1024 (0.25 USD/1 ảnh).\nSau đó chi phí chỉnh sửa ảnh là:\n• Chi phí phân tích ảnh đầu vào 10 USD/ 1M token.\n• Nếu đã có ảnh lưu bộ nhớ  2.5 USD/ 1M token.\n• Chi phí tạo ảnh đầu ra  40 USD/ 1M token.\n ',
    logoUrl: '/image/Logo Open AI cho bảng xếp hạng.png',
    link: 'https://chat.openai.com',
    features:  [
      "Tích hợp sẵn vào Gpt 4o cực kì tiện lợi chỉ việc sử dụng không phải chuyển trang như Dall E.",
      "Hỗ trợ tất cả các kiểu tạo và chỉnh sửa ảnh",
      "• Tạo hình ảnh từ hình ảnh",
      "• Tạo hình ảnh từ mô tả văn bản, giọng nói",
      "• Chỉnh sửa hình ảnh từ hình ảnh mẫu",
      "• Chỉnh sửa hình ảnh từ mô tả văn bản, giọng nói",
    ],
    userRating: 4.8,
    ratingCount: 150,
    isFavorite: false,
  },
  {
    id: 'imagen-4',
    name: 'Imagen 4',
    context: 'Tạo hình ảnh',
    developer: 'Google',
    ranking: 3,
    description: 'Mô hình tạo hình ảnh từ văn bản thế hệ mới nhất của Google, nổi tiếng với khả năng tạo ra hình ảnh quang học giống y như thật mà lại còn có tùy chọn 2k tất cả từ kết cấu vải, giọt nước, lông thú,.. đều đủ chi tiết và chiều sâu. Imagen 4 còn có tùy chọn tốc độ nhanh hơn 10 lần Imagen 3 thật là khủng khiếp.\n+ Đặc biệt Imagen 4 có khả năng hiển thị chữ viết trên ảnh cực kì chính xác, rõ ràng hoàn toàn có thể so với GPT Image 1 tốt hơn hẳn Imagen 3 với tiếng Anh còn tiếng Việt theo như mình đánh giá mới chỉ mức 60%\n+ Hỗ trợ tất cả các kiểu tạo hình ảnh đó là tạo hình ảnh từ hình ảnh, tạo hình ảnh từ mô tả, chỉnh sửa hình ảnh từ hình ảnh, chỉnh sửa hình ảnh từ mô tả.\n+ Người dùng có thể tạo ảnh với nhiều khung hình khác nhau như 16:9 hoặc 9:16 hoặc 1:1 hoặc 2:3 và nhiều phong cách khác nhau từ siêu thực đến trừu tượng.\n+ Giá thì hiện tại có 2 phiên bản của Imagen 4 là \n• Imagen 4: Phiên bản tiêu chuẩn phù hợp hầu hết các tác vụ tạo ảnh thông thường(0.04 USD/1 ảnh)nhưng ở phiên bản này độ chính xác giống prompt mô tả ở mức thấp.\n• Imagen 4 Ultra: Phiên bản cao cấp tập trung trung vào độ chính xác so với prompt mô tả và tạo ảnh chất lượng vượt trội hơn so với Imagen 4 có giá 0.06 USD/1 ảnh.',
    logoUrl: '/image/Logo Gemini cho bảng xếp hạng.png',
    link: 'https://deepmind.google/technologies/imagen/',
    features: [
      "Tạo ảnh siêu chân thực và có chiều sâu có tùy chọn ảnh lên tới 2K.",
"Hỗ trợ nhiều loại kích thước ảnh 16:9 hoặc 9:16 hoặc 2:3 hoặc 1:1.",
      "Hỗ trợ tất cả các kiểu tạo và chỉnh sửa ảnh",
      "• Tạo hình ảnh từ hình ảnh",
      "• Tạo hình ảnh từ mô tả văn bản, giọng nói",
      "• Chỉnh sửa hình ảnh từ hình ảnh mẫu",
      "• Chỉnh sửa hình ảnh từ mô tả văn bản, giọng nói",
    ],
    userRating: 4.7,
    ratingCount: 135,
    isFavorite: true,
  },
  {
    id: 'flowith',
    name: 'Flowith',
    context: 'AI Agent',
    developer: 'Flowith',
    ranking: 5,
    description: 'Flowith là nền tảng AI Agent thế hệ mới với Agent Neo được thiết kế làm việc thông qua giao diện canvas cho phép người dùng quản lý thực hiện các tác vụ phức tạp qua các bước.\n+ Flowith không giống với các nền tảng AI truyền thống như Gemini, Chagpt, Claude dựa trên chat mà nó tạo ra một không gian làm việc khác người dùng có thể xem trực tiếp nó làm việc theo các bước dựa trên ý tưởng đưa vào canvas.\n+ Nền tảng này tích hợp AI Oracle có thể là Gemini hoàn toàn có thể thực hiện liên tục trên 1000 bước hoặc có thể cài đặt thời gian thực hiện các bước chỉ qua câu prompt yêu cầu thực sự vượt trội so với Manus và Genspark chỉ thực hiện được vài chục bước\n+ Flowith tất nhiên vẫn có đầy đủ các ứng dụng thông minh của Manus hay Genspark như:\n• Tự động lập kế hoạch: Tự động lập kế hoạch làm việc trên không gian ảo canvas khi người dùng không cần prompt chi tiết đặc biệt người dùng có thể can thiệp prompt ngay cả khi Agent Neo đang hoạt động.\n• Hệ thống tự phối hợp các AI Agent: Có thể tạo ra một đội AI Agent tự phối hợp với nhau làm việc như một Agent để viêt, Agent để tạo ảnh, Agent để review,.. \n• Hỗ trợ làm việc nhóm: Tất nhiên cái này là cần thiết cho một dự án có nhiều người tham gia, họ có thể chỉnh sửa trực tiếp thông qua phân quyền nhưng có lẽ tính năng chỉ có ở bản trả phí.\n• Tìm kiếm và phản hồi trực tiếp: Có thể tìm kiếm thông tin theo thời gian thực và trả lời trực tiếp thông qua Agent Neo.\n• Tạo tri thức tự động thông qua Knowledge Garden: Agent Neo tự động phân tích thông tin và kết nối tài liệu tải lên thành tri thức có thể sử dụng.\n• Quản lý tác vụ linh hoạt: Người dùng có thể điều chỉnh lập kế hoạch theo thời gian thực thậm chỉ có thể can thiệp khi thấy Agent Neo đang thực hiện các bước không theo ý người dùng. \n• Chi phí với các gói \nGói Free có thể dùng miễn phí với 1000 credit / 1 tháng.\nGói Professional (19.9 USD/ 1 tháng) có thể tạo video với 20000 credit /1 tháng.\nGói Ultimate(49.9 USD/ 1 tháng) có thể tạo video với 50000 credit /1 tháng\n ',
    logoUrl: '/image/Logo flowith.png',
    link: 'https://www.try.flowith.io',
    features:  [
      "Làm việc trên không gian ảo mà vẫn thực hiện đầy đủ các bước.",
"Có thể thực hiện và lập kế hoạch thực hiện lên tới hơn 1000 bước .",
      "Đầy đủ các loại ứng dụng của Ai Agent",
      "• Tự động lập kế hoạch.",
      "• Tự động phối hợp các Ai Agent.",
      "• Hỗ trợ làm việc nhóm.",
      "• Tìm kiếm và phản hồi theo thời gian thực.",
"• Tạo tri thức tự động qua Knowledge Garden.",
"• Quản lý tác vụ linh hoạt.",
    ],
    userRating: 4.6,
    ratingCount: 110,
    isFavorite: false,
  },
  {
    id: 'midjourney',
    name: 'Midjourney',
    context: 'Tạo hình ảnh',
    developer: 'Midjourney',
    ranking: 1,
    description: 'Midjourney là công cụ chuyên tạo hình ảnh nghệ thuật từ văn bản ra mắt năm 2022 chủ yếu hoạt động trên Discord. Nếu ai là dân chuyên sáng tạo, concept art, quảng cáo không lạ gì nền tảng này nữa vì công cụ này khá được ưa chuộng đối với người làm trong lĩnh vực này với những tác phẩm đa phong cách, chi tiết, sắc nét.\n+ Midjourney sử dụng mô hình ngôn ngữ lớn (LLM) phát triển riêng để phân tích tổng hợp tạo ra những bức ảnh giống như tác phẩm sống động với bố cục nghệ thuật.\n+ Midjourney có các lợi thế mà rất nhiều ông lớn trong ngành AI muốn có\n• Tạo ảnh từ mô tả văn bản: Có thể tạo ảnh từ prompt tiếng Việt lẫn tiếng Anh đều có độ chính xác, sáng tạo cao. Tất nhiên là vẫn ưu tiên tiếng Anh hơn.\n• Đa phong cách nghệ thuật: Có thể coi mỗi bức hình tạo ra là một tác phẩm nghệ thuật luôn vì Midjourney hỗ trợ vô vàn phong cách nghệ thuật từ siêu thực đến trừu tượng từ màu sắc đến bố cục.\n• Giao diện dễ sử dụng tương tác tùy chỉnh: Discord là nền tảng lớn thế nào chắc ai cũng biết rồi, chỉ cần hiểu giao diện chat đơn giản là sử dụng được. Cũng giống như nền tảng khác là hoàn toàn có thể nâng cấp, tùy chỉnh bức ảnh thông qua prompt văn bản. \n• Nguồn cảm hứng sáng tạo: Hoạt động từ năm 2022 đến nay thì Midjourney chắc chắn có kho dữ liệu sáng tạo khổng lồ hoàn toàn đủ sức cung cấp ý tưởng độc đáo cho người dùng.\n• Chi phí: Với các gói \nGói Basic là 10 USD / 1 tháng phù hợp với người thử nghiệm nhu cầu cơ bản giới hạn GPU nhanh 3.3 giờ/ tháng còn bình thường thì chúng ta phải đợi tính từ 10 đến 20 phút.\nGói Standard (30 USD /1 tháng) lựa chọn phổ biến với 15 giờ GPU nhanh mỗi tháng và chế độ Relax cho phép tạo ảnh không giới hạn.\nGói Pro (60 USD/1 tháng) và Mega (120 USD/1 tháng) dùng cho người dùng chuyên nghiệp doanh nghiệp cần nhiều tài nguyên với 30 giờ và 60 giờ GPU nhanh tất nhiên là tạo ảnh không giới hạn.\n',
    logoUrl: '/image/Logo Midjourney.png',
    link: 'https://www.midjourney.com',
    features: [
      "Là công cụ chuyên tạo hình ảnh nghệ thuật với rất nhiều phong cách nghệ thuật.",
"Mỗi lần có thể tạo ra được 4 bức ảnh khác nhau dựa trên prompt văn bản tiếng Việt hoặc tiếng Anh .",
"Độ phân giải mỗi bức ảnh rất cao và còn có thể prompt tăng độ phân giải nữa",
      "Giao diện rất dễ tương tác tùy chỉnh",
      "Nguồn cảm hứng sáng tạo cho mọi người.",
      "Chi phí nhỏ nhất là 10 USD / 1 tháng.",
    ],
    userRating: 4.9,
    ratingCount: 200,
    isFavorite: true,
  },
  {
    id: 'n8n',
    name: 'n8n',
    context: 'Tự động hóa',
    developer: 'n8n',
    ranking: 6,
    description: 'n8n là một nền tảng tự động hóa quy trình làm việc (workflow automation) mã nguồn mở, cho phép người dùng kết nối và tích hợp nhiều ứng dụng, dịch vụ khác nhau (đã tích hợp được hơn 400 ứng dụng , dịch vụ) để tự động hóa các tác vụ phức tạp thông qua giao diện kéo-thả trực quan, mà không cần hoặc ít cần viết code.\n+ n8n phù hợp cho cả người không chuyên và lập trình viên nhờ những ưu điểm sau :\n• Giao diện kéo thả cực kì trực quan: n8n hoạt động dựa trên kiến trúc node-based, trong đó mỗi node đại diện cho một hành động hoặc ứng dụng cụ thể (ví dụ: gửi email, gọi API, xử lý dữ liệu). Người dùng có thể tạo các workflow logic bằng cách kết nối các node này thành chuỗi quy trình tự động hóa từ đó tiết kiệm thời gian và giảm lỗi.\n• Hỗ trợ nhiều loại code và tùy chỉnh: Người dùng hoàn toàn có thể sử dụng JavaScript hoặc Python để xử lý logic phức tạp. \n• Tích hợp hơn 400 ứng dụng: Người dùng có thể sử dụng hơn 400 dịch vụ và ứng dụng được tích hợp sẵn trên n8n khá là khiêm tốn so với Make và Zapier nhưng đối với những ứng dụng chưa tích hợp chúng ta có thể kết nối bằng node http request và API nên đây không phải vấn đề lớn.\n• Có thể quản lý và kết hợp nhiều AI Agent: Người dùng có thể kết hợp nhiều AI Agent khác nhau trong cùng một workflow hoặc cùng một hệ thống để xử lý quy trình phức tạp. Với mỗi node AI Agent thì người dùng có thể lựa chọn kết nối tới mô hình LLM của OpenAI, Hugging Face, Anthropic Claude còn ở phần tool đặc biệt có thể cung cấp bộ nhớ cho mô hình LLM với kết nối tới nền tảng như MogoDB, Suparbase, Redis,.. đặc biệt là node Think do n8n tự phát triển giúp cung cấp nhiều tầng suy nghĩ cho mô hình LLM từ đó có thể giúp mô hình LLM thông minh hơn 40%. Tất nhiên node AI Agent cũng đã hỗ trợ chuẩn kết nối LLM mới nhất là MCP, A2A,...\n• Tùy chọn triển khai linh hoạt, làm việc nhóm: Người dùng có thể tự host trên máy chủ riêng có thể quản lý, tùy chỉnh toàn bộ dữ liệu của mình hoặc sử dụng phiên bản cloud (thường rất ít người sử dụng vì giá khá cao) và cả 2 cách sử dụng này đều hỗ trợ làm việc nhóm hiệu quả.\n• Quản lý phiên bản và bảo mật: Hỗ trợ Git control, phân quyền RBAC, mã hóa dữ liệu, audit logs, tích hợp SSO/SAML/LDAP.\n• Cộng đồng người dùng, tài nguyên cực lớn: Vì mã nguồn mở và tính tương thích cao cho nên cộng đồng người sử dụng, diễn đàn, tài nguyên trực tuyến cực kì khổng lồ tạo nên hệ sinh thái mạnh mẽ hỗ trợ người dùng.\n• Chi phí: Đối với n8n cloud thì có gói Starter (24 Euro/1 tháng) bao gồm 2.500 lần thực thi workflow và 5 workflow hoạt động cùng lúc và gói Pro (60 Euro/1 tháng) , bao gồm 10.000 lần thực thi workflow và 15 workflow hoạt động.\nĐối với n8n self host thì bạn được miễn phí phần mềm chỉ phải trả chi phí thuê VPS (4-15 USD/1 tháng) tên miền (3-10 USD/1 năm) chi phí vận hành, bảo trì đặc biệt là không bị giới hạn số lần thực thi và workflow hoạt động vì vậy ở Việt Nam có rất ít người sử dụng gói cloud chỉ có người sử dụng không muốn cài đặt gì thì mới sử dụng gói cloud của n8n.\n ',
    logoUrl: '/image/Logo n8n.png',
    link: 'https://n8n.io/',
    features: [
      "Giao diện kéo thả không hề phức tạp cực kì trực quan giúp tiết kiệm thời gian giảm lỗi.",
"Tích hợp hơn 400 ứng dụng khác nhau và có đầy đủ các mô hình LLM .",
"Có thể quản lý và kết hợp nhiều AI Agent với nhiều tác vụ khác nhau.",
      "Tùy chọn triển khai linh hoạt vì là mã nguồn mở.",
      "Quản lý phiên bản và bảo mật dễ dàng.",
      "Cộng đồng người dùng, tài nguyên khổng lồ.",
    ],
    userRating: 4.5,
    ratingCount: 80,
  },
   {
    id: 'make',
    name: 'Make',
    context: 'Tự động hóa',
    developer: 'Celonis',
    ranking: 8,
    description: 'Make.com là nền tảng tự động hóa quy trình làm việc (workflow automation) không cần mã (no-code/low-code), giúp người dùng kết nối và tự động hóa các ứng dụng quen thuộc như CRM, nền tảng lưu trữ đám mây, công cụ marketing, bán hàng… thông qua giao diện kéo-thả trực quan mà không cần kỹ năng lập trình.\n+ Make.com cho phép người dùng xây dựng các kịch bản tự động hóa (scenario) bằng cách kết nối các module đại diện cho từng hành động cụ thể trong quy trình làm việc. Make có những đặc điểm như sau:\n• Giao diện kéo thả trực quan : Giao diện kéo thả kết nối khá trực quan nhưng khó tùy chỉnh sâu như n8n, và đặc biệt có thể nhìn tổng quát không bị như zapier rất khó nhìn tổng quát.\n• Tích hợp hơn 1500 ứng dụng: Tuy vẫn chưa nhiều và phổ biến bằng Zapier nhưng đây vẫn đủ với hầu hết các công cụ hiện nay email, cloud, crm, thương mại điện tử, đầy đủ các dịch vụ AI của OpenAI, Claude AI, Google AI, Microsoft Azure AI. Còn các ứng dụng chưa kết nối trực tiếp thì đã có API và Http Request nên đây không phải vấn đề lớn.\n• Chỉ hỗ trợ JavaScript: Make hiện nay chỉ hỗ trợ code JavaScript để xử lý các logic phức tạp.\n• Có thể thêm AI để xử lý các quy trình làm việc: Hiện nay Make đã hỗ trợ các node AI để gửi và nhận dữ liệu thông qua API đến các nền tảng LLM của Google, Open AI, Claude,... còn về Make AI Agent thì nền tảng này mới triển khai tháng 4-2025 những AI Agent này được xây dựng dựa trên các mô hình ngôn ngữ lớn (LLM) hàng đầu như OpenAI, Claude AI, Google AI và Microsoft Azure AI, cho phép xử lý ngôn ngữ tự nhiên chính xác và linh hoạt. AI Agent trong Make có khả năng phối hợp với các module khác trong workflow để tự động hóa, thực thi các yêu cầu của người dùng.\n• Xử lý lỗi và gỡ lỗi hoặc có thể tạo scenario nhanh chóng với AI Assistant: Make cung cấp lịch sử chạy chi tiết, dữ liệu vào/ra từng module từ đó có thể cung cấp nhanh chóng cách sửa lỗi hoặc tạo mới scenario để xử lý vấn đề từ AI Assistant của Make nằm ở góc phải màn hình. Tuy người dùng vẫn phải sửa lỗi hoặc tạo scenario thủ công nhưng nên sử dụng AI Assistant của Make vì thực sự rất tốt nhưng mới triển khai ở dạng Beta thôi trong khi n8n và Zapier chưa triển khai.\n• Cộng đồng người dùng, tài nguyên cực lớn: Cộng đồng người dùng cũng rất lớn nhưng ý kiến cá nhân so với Zapier, n8n có thể chưa lớn bằng.\n• Chi phí: \nGói Free được dùng miễn phí với giới hạn 1000 lượt chạy / 1 tháng sau 1 tháng reset lại và 2 kịch bản chạy liên tục (active) 5 Mb file size (tức là gửi khoảng 4 bức ảnh lúc trở lên cùng lúc đến server thì make không thể xử lý được)\nGói Core với giá 9 - 11 USD/1 tháng với giới hạn 10.000 lượt chạy / 1 tháng sau 1 tháng reset lại , 100 Mb file size và không giới hạn kịch bản chạy active đó cũng là lý do người sử dụng n8n cloud có rất ít vì đối với người không biết nhiều về kĩ thuật thì hay dùng make vì có giá rẻ hơn.\nGói Pro với giá 16 - 19 USD/1 tháng với giới hạn 10.000 lượt chạy / 1 tháng sau 1 tháng reset lại , 250 Mb file size (hoàn toàn có thể xử lý nhiều video ở gói này ) và không giới hạn kịch bản chạy active đặc biệt hỗ trợ biến tùy chỉnh, đầu vào kịch bản, tìm kiếm nhật ký thực thi toàn văn bản.\nGói Teams với giá 29 - 34.12 USD/1 tháng với giới hạn 10.000 lượt chạy / 1 tháng sau 1 tháng reset lại , 500 Mb file size (hoàn toàn có thể xử lý nhiều video hơn ở gói này ) và không giới hạn kịch bản chạy active gói này có hỗ trợ thêm nhiều nhóm và phân quyền người dùng.\n.\n ',
    logoUrl: '/image/Logo Make.com.png',
    link: 'https://www.make.com/',
    features: [
      "Giao diện kéo thả trực quan.",
"Tích hợp hơn 1500 ứng dụng khác nhau và có đầy đủ các mô hình LLM .",
"AI Agent đã có thể phối hợp với module trong scenario để tự động hóa yêu cầu của người dùng rất tốt nhưng vẫn chưa so sánh được với Agent của n8n.",
      "Có thể gỡ lỗi sửa lỗi hoặc hướng dẫn tạo scenario với AI Assistant.",
      "Có gói miễn phí hoàn toàn có thể sử dụng được.",
      "Cộng đồng người dùng, tài nguyên rất lớn.",
    ],
    userRating: 4.3,
    ratingCount: 75,
  },
  {
    id: 'tavily-ai',
    name: 'Tavily AI',
    context: 'API Tìm kiếm',
    developer: 'Tavily',
    ranking: 7,
    description: 'Tavily AI là công cụ tìm kiếm và nghiên cứu hỗ trợ trí tuệ nhân tạo, được thiết kế tối ưu cho các mô hình ngôn ngữ lớn (LLM) và các hệ thống tạo-tái-tìm kiếm (RAG). Tavily cung cấp kết quả tìm kiếm chính xác, cập nhật theo thời gian thực, kèm theo trích dẫn nguồn đáng tin cậy, giúp giảm thiểu sai sót do ảo giác thông tin hoặc dữ liệu lỗi thời.\n+ Tavily có 4 tính năng chính qua API là tìm kiếm (Tavily search) trích xuất (Tavily extract) cào dữ liệu web (Tavily crawl) sơ đồ thông tin (Tavily map) được tổng hợp lại các ưu điểm sau:\n• Tìm kiếm thời gian thực: Kết hợp tìm kiếm web trực tiếp từ nhiều nguồn (Google, Bing, DuckDuckGo, v.v.) để cung cấp dữ liệu mới nhất và nhanh nhất cho các LLM hoặc AI Agen hoặc hệ thống RAG và từ đó tổng hợp lại thông tin tất nhiên là có trích dẫn nguồn để đảm bảo tính minh bạch và chính xác.\n• API của Tavily cực kì thân thiện với LLM và RAG: API của Tavily cực kì thân thiện với LLM giúp Tavily có thể tham gia dễ dàng vào các workflow tự động hóa công việc không giống Perplexity tập trung vào trả lời hỏi đáp với AI dựa trên các dữ liệu tổng hợp và web search.\n• Hỗ trợ cả web crawl và web extract: Người dùng hoàn toàn có thể dựa trên AI để trích xuất nội dung văn bản đơn thuần của web thông qua Tavily crawl hoặc có thể chọn trích xuất nội dung đã được AI xử lý giúp phân biệt và chuẩn hóa tiêu đề, đoạn văn, metadata, bảng biểu, và các phần nội dung có ý nghĩa khác trên trang web thông qua Tavily extract với AI giúp giảm thiểu các công đoạn xử lý dữ liệu trong RAG.\n• Hỗ trợ tạo map cho web: Tavily sẽ trả về danh sách cả url được phát hiện trong website đó giúp người dùng có cái nhìn tổng quan về web đó, nếu ai đã dùng Webflow hoặc Relume hoặc làm SEO thì sẽ hiểu rõ về site map.\n• Hỗ trợ đa dạng nguồn dữ liệu: Ngoài dữ liệu web công khai, Tavily còn tích hợp các nguồn dữ liệu nội bộ riêng tư về tài chính, mã hóa, tin tức, v.v., giúp mở rộng phạm vi thông tin.\n• Chi phí: Tavly tính phí dựa trên số lần gửi và nhận thông tin qua API thông qua credit với gói miễn phí là 1000 credit / 1 tháng khi hết thì mua thêm là 0.008 USD/1 credit \nGói Project là 30 USD / 1 tháng với  4000 credit / 1 tháng khá là dư dùng.\n',
    logoUrl: '/image/Logo Tavily.png',
    link: 'https://tavily.com/',
    features: [
      "Tìm kiếm theo thời gian thực từ đó tổng hợp lại thông tin dựa trên AI có trích dẫn nguồn.",
"API cực kì thân thiện với LLM và RAG giúp Tavily dễ dàng tham gia vào các workflow .",
"Hỗ trợ cả web crawl và web extract và đều dựa trên AI.",
      "Hỗ trợ tạo map cho web",
      "Hỗ trợ đa dạng nguồn dữ liệu.",
      "Gói miễn phí hoàn toàn có thể dùng cho nghiên cứu sinh, sinh viên.",
    ],
    userRating: 4.4,
    ratingCount: 60,
  },
  {
    id: 'notion-ai',
    name: 'Notion AI',
    context: 'Hỗ trợ viết',
    developer: 'Notion',
    ranking: 9,
    description: 'Tích hợp AI vào không gian làm việc Notion để hỗ trợ viết, tóm tắt và lên ý tưởng.',
    logoUrl: '/image/notion-ai-logo.png',
    link: 'https://www.notion.so/product/ai',
    features: [],
    userRating: 4.2,
    ratingCount: 95,
  },
  {
    id: 'stable-diffusion-3-tool',
    name: 'Stable Diffusion 3',
    context: 'Tạo hình ảnh',
    developer: 'Stability AI',
    ranking: 4,
    description: 'Stable Diffusion 3 là phiên bản mới nhất và tiên tiến nhất của mô hình tạo ảnh từ văn bản do Stability AI phát triển, mang đến nhiều cải tiến vượt trội về chất lượng hình ảnh, khả năng xử lý nhiều đối tượng trong cùng một prompt, và khả năng hiển thị văn bản chính xác hơn trong ảnh.\n+ Stable Diffusion 3 là mã nguồn mở, cho phép tự do tải về, chạy offline và tùy chỉnh ngay trên máy chủ của người dùng luôn.\n+ Stable Diffusion 3 không giống với Midjourney hay Leonardo nó có những đặc điểm đặc biệt dưới đây vì vậy để khai thác tối đa mô hình hoặc tinh chỉnh chi tiết thì người dùng cần biết nhiều kĩ thuật prompt:\n• Stable Diffusion 3 sử dụng kiến trúc Multimodal Diffusion Transformer (MMDiT) với MMDiT là sự kết hợp biểu diễn riêng biệt cho ngôn ngữ và hình ảnh, sử dụng attention và MLP để xử lý tuần tự, giúp mô hình hiểu sâu hơn về nội dung prompt.\n• Tùy chọn kích thước mô hình đa dạng: Từ 800 triệu đến 8 tỷ tham số, phù hợp với nhiều loại phần cứng từ máy tính cá nhân đến GPU doanh nghiệp.\n• Khả năng tùy chỉnh và fine-tuning dễ dàng: Dễ dàng điều chỉnh mô hình với bộ dữ liệu nhỏ để tạo ra các phiên bản chuyên biệt theo nhu cầu.\n• Cải thiện xử lý đa đối tượng (multi-subject prompts): Mô hình hiểu và tái tạo chính xác nhiều đối tượng cùng lúc trong một prompt, giúp tạo ra hình ảnh phức tạp và chi tiết hơn.\n• Cam kết an toàn và trách nhiệm: Stability AI tích hợp nhiều biện pháp bảo vệ để hạn chế việc sử dụng mô hình vào các mục đích xấu, đồng thời hợp tác với cộng đồng và chuyên gia để phát triển bền vững.\n• Có phiên bản miễn phí trên Hugging Face: Chúng ta có thể hoàn toàn kết nối với Stable Diffusion 3 thông qua API của Hugging Face mà không cần cài thêm bất cứ phần mềm nào, cực kì tiện lợi.\n  ',
    logoUrl: '/image/Logo Stability AI.png',
    link: 'https://stability.ai/stablediffusion3',
    features: [
      "Stable Diffusion 3 là mã nguồn mở nền hoàn toàn có thể tải về chạy offline ngay trên máy chủ của người sử dụng.",
"Sử dụng kiến trúc MMDiT biểu diễn riêng biệt ngôn ngữ và hình ảnh xử lý tuần tự giúp nền tảng hiểu prompt hơn .",
"Tùy chọn kích thước mô hình đa dạng.",
      "Khả năng tùy chỉnh và fine tuning dễ dàng",
      "Cải thiện xử lý đa đối tượng trong một prompt.",
      "Kết nối miễn phí qua API của Hugging Face.",
    ],
    userRating: 4.6,
    ratingCount: 140,
    isFavorite: false,
  },
];

export const mockAIModels: AIModel[] = [
  {
    id: 'gemini-2.5-pro',
    name: 'Gemini 2.5 Pro',
    type: 'Mô hình ngôn ngữ lớn',
    developer: 'Google',
    description: `+ Gemini 2.5 Pro (cập nhật mới nhất tháng 06/2025) là mô hình đa phương thức (multimodal) mạnh mẽ nhất trong dòng Gemini do Google phát triển.
+ Gemini 2.5 Pro có thể hiểu và tạo ra nội dung dữ liệu dựa trên nhiều đầu vào khác nhau như văn bản, hình ảnh, video, âm thanh.
+ Mô hình hỗ trợ tới 1 triệu token trong một lần nhập liệu (tương đương khoảng 1,5 triệu từ hoặc 5.000 trang văn bản), với kế hoạch mở rộng lên 2 triệu token trong tương lai gần.Nhờ vậy, Gemini 2.5 Pro có thể xử lý các tài liệu dài, mã nguồn lớn (hơn 50.000 dòng code), video dài gần 1 giờ hoặc âm thanh lên đến 19 giờ trong một lần tương tác duy nhất.
+ Bạn có thể dùng thử Gemini 2.5 Pro ở trên Google AI Studio, Vertex AI, Gemini API.Ngoài ra, Gemini 2.5 Pro cũng được tích hợp trong ứng dụng Gemini dành cho người dùng cao cấp, với các tính năng mới như tăng gấp đôi giới hạn truy vấn, hỗ trợ camera trực tiếp và chia sẻ màn hình trong tính năng Stream.`,
    logoUrl: '/image/Logo Gemini cho bảng xếp hạng.png',
    link: 'https://deepmind.google/technologies/gemini/#introduction',
    userRating: 4.9,
    ratingCount: 250,
    features: [
      "Độ dài ngữ cảnh (context window) có thể xử lý 1 lần là 1 triệu token→ Tức là có thể xử lý khoảng 1,5 triệu từ hoặc 5.000 trang văn bản trong 1 lần xử lý .",
      "Chỉ số thông minh 70 →Dựa trên trung bình các điểm benmark là",
      "• MMLU-Pro (Reasoning & Knowledge) 86%",
      "• GPQA Diamond (Scientific Reasoning) 84%",
      "• Humanity's Last Exam (Reasoning & Knowledge) 21.1%",
      "• LiveCodeBench (Coding) 80%",
      "• SciCode (Coding) 43%",
      "• HumanEval (Coding)",
      "• MATH-500 (quantitative reasoning) 97%",
      "• AIME 2024 (Competition Math) 89%",
      "Giá trung bình 3.44 USD/ 1 triệu token → Dựa trên các thông số giá",
      "• Giá đầu vào 1.25 USD / 1 triệu token.",
      "• Giá đầu ra 10 USD / 1 triệu token.",
      "Tốc độ sinh token khá nhanh là 143.9 token /s.",
      "Độ trễ 36.13s là thời gian chờ trung bình từ khi bấm “enter” gửi thông tin đến khi mô hình trả lời token đầu tiên."
    ],
    isFavorite: false,
    contextLengthToken: '1m',
    intelligenceScore: 70,
    pricePerMillionTokens: 3.44,
    speedTokensPerSecond: 143.9,
    latencyFirstChunkSeconds: 36.13,
  },
  {
    id: 'grok-3-mini-reasoning-high',
    name: 'Grok 3 mini Reasoning (high)',
    type: 'Mô hình ngôn ngữ lớn',
    developer: 'xAI',
    description: `+Grok 3 Mini là mô hình ngôn ngữ mini do xAI phát triển, tích hợp sâu với nền tảng X (Twitter). Phiên bản "Mini" của Grok 3 được tối ưu để giữ được khả năng tuyệt vời khi bật chế độ suy luận cao (reasoning (high)), trong khi vẫn đảm bảo tốc độ phản hồi nhanh và khả năng triển khai nhẹ hơn trên nhiều nền tảng.
+Triển khai linh hoạt: Nhờ dung lượng nhỏ hơn, Grok 3 Mini dễ dàng tích hợp trên nhiều nền tảng, từ web, di động đến các ứng dụng doanh nghiệp.
+ Grok 3 mini do có sự hỗ trợ từ mạng xã hội X (Twitter) từ đó có khả năng truy cập và cập nhật dữ liệu thời gian thực từ X, giúp cung cấp thông tin mới nhất và phù hợp với các sự kiện đang diễn ra .
+ Phong cách phản hồi tự nhiên, thân thiện được học từ những người dùng mạng xã hội X nên Grok 3 và Grok 3 mini được đánh giá rất cao với cách trả lời gần gũi, hài hước và dễ tiếp cận với người dùng Việt Nam.`,
    logoUrl: '/image/Logo Grok cho bảng xếp hạng.png',
    link: '#',
    userRating: 4.8,
    ratingCount: 180,
    features: [
      "Độ dài ngữ cảnh (context window) có thể xử lý 1 lần là 1 triệu token.",
      "• Tức là có thể xử lý khoảng 1,5 triệu từ hoặc 5.000 trang văn bản trong 1 lần xử lý.",
      "Chỉ số thông minh 67",
      "• Dựa trên trung bình các điểm benmark là",
      "• MMLU-Pro (Reasoning & Knowledge) 83%",
      "• GPQA Diamond (Scientific Reasoning) 79%",
      "• Humanity's Last Exam (Reasoning & Knowledge) 11.1%",
      "• LiveCodeBench (Coding) 70%",
      "• SciCode (Coding) 41%",
      "• HumanEval (Coding) 98%",
      "• MATH-500 (Quantitative reasoning) 99%",
      "• AIME 2024 (Competition Math) 93%",
      "Giá trung bình 0.35 USD / 1 triệu token",
      "• Dựa trên các thông số giá",
      "• Giá đầu vào 0.3 USD / 1 triệu token.",
      "• Giá đầu ra 0.5 USD / 1 triệu token.",
      "Tốc độ sinh token khá nhanh là 209.2 token /s.",
      "Độ trễ 0.32s là thời gian chờ trung bình từ khi bấm “enter” gửi thông tin đến khi mô hình trả lời token đầu tiên."
    ],
    contextLengthToken: '1m',
    intelligenceScore: 67,
    pricePerMillionTokens: 0.35,
    speedTokensPerSecond: 209.2,
    latencyFirstChunkSeconds: 0.32,
  },
  {
    id: 'openai-o3-pro',
    name: 'Open AI o3-pro',
    type: 'Mô hình ngôn ngữ lớn',
    developer: 'OpenAI',
    description: `+ OpenAI o3 Pro là phiên bản nâng cấp mới nhất thuộc dòng mô hình lý luận o3, chính thức ra mắt vào ngày 10/6/2025. Đây là bước tiến vượt bậc trong công nghệ AI của OpenAI, được tích hợp trong các gói ChatGPT Pro, Team, Enterprise và API, nhằm thay thế hoàn toàn phiên bản o1 Pro trước đó.
+ OpenAI khuyến nghị người dùng lựa chọn o3 Pro cho các tác vụ đòi hỏi độ tin cậy và độ chính xác cao, nơi việc chờ đợi vài phút là xứng đáng.`,
    logoUrl: '/image/Logo Open AI cho bảng xếp hạng.png',
    link: 'https://openai.com/',
    userRating: 4.9,
    ratingCount: 320,
    features: [
      "Độ dài ngữ cảnh (context window) có thể xử lý một lần là 200 nghìn token→ Tức là có thể xử lý khoảng 150 nghìn từ hoặc 600 trang văn bản trong 1 lần xử lý .",
      "Chỉ số thông minh 71 → Dựa trên trung bình các điểm benmark là",
      "• MMLU-Pro (Reasoning & Knowledge) 85%",
      "• GPQA Diamond (Scientific Reasoning) 84%",
      "• Humanity's Last Exam (Reasoning & Knowledge) 18.2%",
      "• LiveCodeBench (Coding) 81%",
      "• SciCode (Coding) 42%",
      "• HumanEval (Coding) 99%",
      "• MATH-500 (Quantitative reasoning) 99%",
      "• AIME 2024 (Competition Math) 93%",
      "Giá trung bình 35 USD / 1 triệu token → Dựa trên các thông số giá",
      "• Giá đầu vào 20 USD / 1 triệu token.",
      "• Giá đầu ra 80 USD / 1 triệu token.",
      "Tốc độ sinh token là 23.5 token /s.",
      "Độ trễ 110.86s là thời gian chờ trung bình từ khi bấm “enter” gửi thông tin đến khi mô hình trả lời token đầu tiên."
    ],
    isFavorite: false,
    contextLengthToken: '200k',
    intelligenceScore: 71,
    pricePerMillionTokens: 35,
    speedTokensPerSecond: 23.5,
    latencyFirstChunkSeconds: 110.86,
  },
   {
    id: 'gemini-2.5-flash-reasoning',
    name: 'Gemini 2.5 Flash (Reasoning)',
    type: 'AI Đa phương thức',
    developer: 'Google',
    description: `+ Gemini 2.5 Flash (Reasoning) cập nhật mới nhất là tháng 6-2025 là phiên bản nâng cấp của Gemini 2.0 Flash đặc biệt với chắc năng suy luận nâng cao (Reasoning) mang đến hiệu suất ở mức chấp nhận được kết hợp với chi phí và độ mượt mà.
+ Nâng cấp từ Gemini 2.0 flash nên độ dài ngữ cảnh (context window) ở mức 1 triệu token là mức trở nên bình thường đối với nhà Google.
+ Gemini 2.5 flash đặc biệt phù hợp với các ứng dụng chatbot hoặc web /app cần phản hồi nhanh mà vẫn giữ được sự thông minh. Vì vậy sẽ là đối thủ trực tiếp với Claude 4 Sonnet Thinking nhưng Claude 4 Sonnet có giá chát hơn hẳn.`,
    logoUrl: '/image/Logo Gemini cho bảng xếp hạng.png',
    link: 'https://deepmind.google/technologies/gemini/',
    userRating: 4.9,
    ratingCount: 195,
    features: [
      "Độ dài ngữ cảnh (context window) có thể xử lý một lần là 1 triệu token",
      "• Tức là có thể xử lý khoảng 1,5 triệu từ hoặc 5.000 trang văn bản trong 1 lần xử lý.",
      "Chỉ số thông minh 65",
      "• Dựa trên trung bình các điểm benmark là",
      "• MMLU-Pro (Reasoning & Knowledge) 83%",
      "• GPQA Diamond (Scientific Reasoning) 79%",
      "• Humanity's Last Exam (Reasoning & Knowledge) 11.1%",
      "• LiveCodeBench (Coding) 70%",
      "• SciCode (Coding) 39%",
      "• HumanEval (Coding) 96%",
      "• MATH-500 (Quantitative reasoning) 98%",
      "• AIME 2024 (Competition Math) 82%",
      "Giá trung bình 0.99 USD / 1 triệu token",
      "• Giá đầu vào 1.1 USD / 1 triệu token.",
      "• Giá đầu ra 4.4 USD / 1 triệu token.",
      "Tốc độ sinh token là 351.2 token /s.",
      "Độ trễ 13.24s là thời gian chờ trung bình từ khi bấm “enter” gửi thông tin đến khi mô hình trả lời token đầu tiên."
    ],
    contextLengthToken: '1m',
    intelligenceScore: 65,
    pricePerMillionTokens: 0.99,
    speedTokensPerSecond: 351.2,
    latencyFirstChunkSeconds: 13.24,
  },
  {
    id: 'claude-4-opus-thinking',
    name: 'Claude 4 Opus Thinking',
    type: 'Mô hình ngôn ngữ lớn',
    developer: 'Anthropic',
    description: `+ Claude 4 Opus Thinking là phiên bản cao cấp nhất trong dòng mô hình Claude 4 của Anthropic ( vừa ra mắt tháng 5 năm 2025) Claude Opus 4 được tối ưu đặc biệt cho các tác vụ đòi hỏi khả năng suy luận sâu với nhiều bước phức tạp đi kèm độ chính xác.
+ Claude 4 Opus Thinking thật sự có lẽ là mô hình thông minh nhất hiện nay vì các lý do
+ Claude 4 Opus có khả năng suy luận qua nhiều bước (multi-step reasoning), giúp mô hình xử lý vấn đề logic và có hệ thống, giảm tối đa"lối tắt" hay thủ thuật không những thế nó còn bổ sung chế độ Thinking cho phép mô hình tạm dừng để cân nhắc kỹ lưỡng nhiều bước trước khi đưa ra câu trả lời cuối cùng, điều đó giúp nó thông minh hơn 65% so với Claude 3.7 Sonnet.
+ Trong điểm thông minh ở đây không bổ sung benchmark như SWE-bench (78.3%) và Terminal-bench (85.2%) mà Claude 4 Opus Thinking đạt được chứ không là nó bỏ xa các mô hình GPT-4.1 (54.6%) và Gemini 2.5 Pro (63.8%).
+ Claude 4 Opus Thinking còn rất thân thiện và khả năng hoạt động ổn định với tiếng Việt. Mô hình này là ít lỗi nhất và ổn định nhất so với GPT 4.1 và Gemini 2.5 Pro nếu ai đã từng trải nghiệm nhưng có nhược điểm là giá rất cao vì vậy chỉ phù hợp với những ai có điều kiện và mô hình là doanh nghiệp.`,
    logoUrl: '/image/Logo Claude AI cho bảng xếp hạng.png',
    link: 'https://www.anthropic.com/news/claude-3-family',
    userRating: 4.9,
    ratingCount: 280,
    features: [
        "Độ dài ngữ cảnh (context window) có thể xử lý một lần là 200 nghìn token→ Tức là có thể xử lý khoảng 150 nghìn từ hoặc 600 trang văn bản trong 1 lần xử lý .",
        "Chỉ số thông minh 64 →Dựa trên trung bình các điểm benmark là",
        "• MMLU-Pro (Reasoning & Knowledge) 87%",
        "• GPQA Diamond (Scientific Reasoning) 80%",
        "• Humanity's Last Exam (Reasoning & Knowledge) 11.7%",
        "• LiveCodeBench (Coding) 64%",
        "• SciCode (Coding) 40%",
        "• HumanEval (Coding)",
        "• MATH-500 (Quantitative reasoning) 98%",
        "• AIME 2024 (Competition Math) 76%",
        "Giá trung bình 30.0 USD / 1 triệu token → Dựa trên các thông số giá",
        "• Giá đầu vào 15.0 USD / 1 triệu token.",
        "• Giá đầu ra 75.0 USD / 1 triệu token.",
        "Tốc độ sinh token là 55.5 token /s.",
        "Độ trễ 3.22s là thời gian chờ trung bình từ khi bấm “enter” gửi thông tin đến khi mô hình trả lời token đầu tiên."
    ],
    isFavorite: false,
    contextLengthToken: '200k',
    intelligenceScore: 64,
    pricePerMillionTokens: 30.00,
    speedTokensPerSecond: 55.5,
    latencyFirstChunkSeconds: 3.22,
  },
  {
    id: 'qwen3-235b-reasoning',
    name: 'Qwen3 235B (Reasoning)',
    type: 'Mô hình ngôn ngữ lớn',
    developer: 'Alibaba',
    description: `+ Qwen3-235B-A22B, hay gọi tắt là Qwen 235B, là phiên bản flagship mới nhất trong dòng mô hình Qwen do Alibaba phát triển, ra mắt vào đầu năm 2025. Đây là một trong những mô hình Al tiên tiến nhất hiện nay, nổi bật với khả năng suy luận đa bước sâu sắc, hiệu suất cao trong toán học, lập trình và xử lý ngôn ngữ tự nhiên, đồng thời hỗ trợ đa ngôn ngữ lên đến 119 ngôn ngữ và phương ngữ.
+ Mô hình Qwen 235B hoạt động ở 2 chế độ đặc biệt ở chế độ Thinking (chế độ suy nghĩ): Mô hình thực hiện suy luận từng bước, phù hợp với các bài toán phức tạp như toán học, lập trình, và các tác vụ logic đa bước, còn khi không bật Thinking thì mô hình chỉ đáp ứng những câu hỏi đơn giản yêu cầu truy xuất nhanh.
+ Mô hình sở hữu 235 tỷ tham số tổng thể, trong đó mỗi truy vấn chỉ kích hoạt 22 tỷ tham số, giúp giảm đáng kể chi phí tính toán và độ trễ mà vẫn duy trì hiệu suất .`,
    logoUrl: '/image/Logo Qwen cho bảng xếp hạng.png',
    link: '#',
    userRating: 4.9,
    ratingCount: 150,
    features: [
        "Độ dài ngữ cảnh (context window) có thể xử lý một lần là 128 nghìn token → Tức là có thể xử lý khoảng 120 nghìn từ hoặc 400 trang văn bản trong 1 lần xử lý.",
        "Chỉ số thông minh 62 →Dựa trên trung bình các điểm benmark là",
        "• MMLU-Pro (Reasoning & Knowledge) 83%",
        "• GPQA Diamond (Scientific Reasoning) 70%",
        "• Humanity's Last Exam (Reasoning & Knowledge) 11.7%",
        "• LiveCodeBench (Coding) 62%",
        "• SciCode (Coding) 40%",
        "• HumanEval (Coding)",
        "• MATH-500 (Quantitative reasoning) 93%",
        "• AIME 2024 (Competition Math) 84%",
        "Giá trung bình 2.63 USD / 1 triệu token → Dựa trên các thông số giá",
        "• Giá đầu vào 0.7 USD / 1 triệu token.",
        "• Giá đầu ra 8.4 USD / 1 triệu token.",
        "Tốc độ sinh token là 71.1 token /s.",
        "Độ trễ 1.13s là thời gian chờ trung bình từ khi bấm “enter” gửi thông tin đến khi mô hình trả lời token đầu tiên."
    ],
    contextLengthToken: '128k',
    intelligenceScore: 62,
    pricePerMillionTokens: 2.63,
    speedTokensPerSecond: 71.1,
    latencyFirstChunkSeconds: 1.13,
  },
  {
    id: 'openai-o4-mini-high',
    name: 'Open AI o4-mini (high)',
    type: 'Mô hình ngôn ngữ lớn',
    developer: 'OpenAI',
    description: `+ OpenAI o4 Mini (High) là phiên bản nâng cấp hiệu suất của dòng mô hình o4 Mini, được ra mắt vào đầu năm 2025. Đây là biến thể được tối ưu để xử lý các tác vụ suy luận phức tạp hơn, phù hợp với các nhu cầu nghiên cứu khoa học nâng cao, lập trình mã nguồn phức tạp và giải quyết các bài toán toán học khó khăn, trong khi vẫn giữ được chi phí vận hành thấp và tốc độ phản hồi nhanh hơn nhiều so với các mô hình cao cấp như o3 hay GPT-4.
+ Mặc dù có sức mạnh tính toán gần bằng các mô hình cao cấp, o4 Mini (High) vẫn duy trì chi phí vận hành hợp lý, giúp người dùng tiết kiệm ngân sách so với việc sử dụng các mô hình lớn hơn. Tốc độ phản hồi của mô hình vẫn nhanh, tuy có độ trễ cao hơn một chút so với o4 Mini tiêu chuẩn do yêu cầu tính toán phức tạp hơn.
+ OpenAI o4 Mini (High) phù hợp với các ứng dụng đòi hỏi độ chính xác cao và suy luận chuyên sâu như soạn truy vấn SQL phức tạp, giải thích các khái niệm khoa học nâng cao, phát triển phần mềm phức tạp và nghiên cứu chuyên ngành.`,
    logoUrl: '/image/Logo Open AI cho bảng xếp hạng.png',
    link: 'https://openai.com/',
    userRating: 4.9,
    ratingCount: 210,
    features: [
      "Độ dài ngữ cảnh (context window) có thể xử lý một lần là 200 nghìn token→ Tức là có thể xử lý khoảng 150 nghìn từ hoặc 600 trang văn bản trong 1 lần xử lý .",
      "Chỉ số thông minh 70 →Dựa trên trung bình các điểm benmark là",
      "• MMLU-Pro (Reasoning & Knowledge) 83%",
      "• GPQA Diamond (Scientific Reasoning) 78%",
      "• Humanity's Last Exam (Reasoning & Knowledge) 17.5%",
      "• LiveCodeBench (Coding) 80%",
      "• SciCode (Coding) 47%",
      "• HumanEval (Coding) 99%",
      "• MATH-500 (Quantitative reasoning) 99%",
      "• AIME 2024 (Competition Math) 94%",
      "Giá trung bình 1.93 USD / 1 triệu token → Dựa trên các thông số giá",
      "• Giá đầu vào 1.1 USD / 1 triệu token.",
      "• Giá đầu ra 4.5 USD / 1 triệu token.",
      "Tốc độ sinh token khá nhanh là 138.6 token /s.",
      "Độ trễ 34.8s là thời gian chờ trung bình từ khi bấm “enter” gửi thông tin đến khi mô hình trả lời token đầu tiên."
    ],
    isFavorite: false,
    contextLengthToken: '200k',
    intelligenceScore: 70,
    pricePerMillionTokens: 1.93,
    speedTokensPerSecond: 138.6,
    latencyFirstChunkSeconds: 34.8,
  },
  {
    id: 'qwen3-32b-reasoning',
    name: 'Qwen3 32B (Reasoning)',
    type: 'Mô hình ngôn ngữ lớn',
    developer: 'Alibaba',
    description: `+ Qwen3 32B là phiên bản cận flagship trong dòng mô hình Qwen3 do Alibaba phát triển, ra mắt đầu năm 2025, đánh dấu bước tiến lớn trong khả năng suy luận đa bước, xử lý toán học, lập trình và ngôn ngữ tự nhiên. Với 32 tỷ tham số, Qwen3 32B nổi bật nhờ kiến trúc tối ưu, hỗ trợ hai chế độ vận hành linh hoạt: Reasoning Mode (suy luận từng bước cho các tác vụ phức tạp) và Non-Reasoning/Mode (phản hồi nhanh cho các câu hỏi đơn giản), giúp cân bằng hiệu suất và tốc độ theo nhu cầu sử dụng.
+ Mô hình cho phép chuyển đổi mượt mà giữa suy luận sâu sắc (reasoning) và phản hồi nhanh (non reasoning), giúp xử lý hiệu quả các bài toán phức tạp như toán học, lập trình, logic đa bước cũng như các tác vụ hội thoại thông thường.
+ Qwen3 32B được phát hành dưới dạng mã nguồn mở, cho phép các nhà phát triển dễ dàng tích hợp và tùy chỉnh theo nhu cầu, đồng thời có thể truy cập qua API của các nền tảng như Lambda hoặc Groqt.`,
    logoUrl: '/image/Logo Qwen cho bảng xếp hạng.png',
    link: '#',
    userRating: 4.9,
    ratingCount: 165,
    features: [
        "Độ dài ngữ cảnh (context window) có thể xử lý một lần là 128 nghìn token → Tức là có thể xử lý khoảng 120 nghìn từ hoặc 400 trang văn bản trong 1 lần xử lý.",
        "Chỉ số thông minh 59 →Dựa trên trung bình các điểm benmark là",
        "• MMLU-Pro (Reasoning & Knowledge) 80%",
        "• GPQA Diamond (Scientific Reasoning) 67%",
        "• Humanity's Last Exam (Reasoning & Knowledge) 8.3%",
        "• LiveCodeBench (Coding) 55%",
        "• SciCode (Coding) 35%",
        "• HumanEval (Coding)",
        "• MATH-500 (Quantitative reasoning) 96%",
        "• AIME 2024 (Competition Math) 81%",
        "Giá trung bình 2.63 USD / 1 triệu token → Dựa trên các thông số giá",
        "• Giá đầu vào 0.7 USD / 1 triệu token.",
        "• Giá đầu ra 8.4 USD / 1 triệu token.",
        "Tốc độ sinh token là 60.2 token /s.",
        "Độ trễ 1.18s là thời gian chờ trung bình từ khi bấm “enter” gửi thông tin đến khi mô hình trả lời token đầu tiên."
    ],
    contextLengthToken: '128k',
    intelligenceScore: 59,
    pricePerMillionTokens: 2.63,
    speedTokensPerSecond: 60.2,
    latencyFirstChunkSeconds: 1.18,
  },
  {
    id: 'qwenq-32b',
    name: 'QwenQ-32B',
    type: 'Mô hình ngôn ngữ lớn',
    developer: 'Alibaba',
    description: `+ Qwen QwQ-32B (viết tắt của "Qwen With Questions") là mô hình ngôn ngữ lớn (LLM) với 32 tỷ tham số do Alibaba phát triển, ra mắt đầu năm 2025.
+ Mặc dù chỉ có 32 tỷ tham số, QwQ-32B được tối ưu để hoạt động hiệu quả với yêu cầu tài nguyên thấp hơn nhiều so với các mô hình lớn hơn như DeepSeek-R1 (671 tỷ tham số). Mô hình chỉ cần khoảng 24GB VRAM để chạy, phù hợp với các GPU phổ biến như Nvidia RTX 4090 hoặc cao hơn, giúp mở rộng khả năng triển khai trên nhiều thiết bị.
+ QwQ-32B được phát hành dưới giấy phép Apache 2.0 (mã nguồn mở), cho phép các nhà phát triển, doanh nghiệp và cộng đồng nghiên cứu sử dụng, tùy chỉnh và tích hợp mô hình một cách tự do.
+ Mô hình vẫn còn một số hạn chế như khả năng trộn lẫn ngôn ngữ hoặc chuyển đổi mã không mong muốn, có thể dẫn đến phản hồi dài dòng hoặc vòng lặp suy luận đệ quy. Ngoài ra, cần áp dụng các biện pháp an toàn để đảm bảo hiệu suất và tránh các kết quả không phù hợp khi triển khai thực tế.`,
    logoUrl: '/image/Logo Qwen cho bảng xếp hạng.png',
    link: '#',
    userRating: 4.9,
    ratingCount: 140,
    features: [
        "Độ dài ngữ cảnh (context window) có thể xử lý một lần là 131 nghìn token → Tức là có thể xử lý khoảng 135 nghìn từ hoặc 500 trang văn bản trong 1 lần xử lý.",
        "Chỉ số thông minh 58 →Dựa trên trung bình các điểm benmark là",
        "• MMLU-Pro (Reasoning & Knowledge) 80%",
        "• GPQA Diamond (Scientific Reasoning) 67%",
        "• Humanity's Last Exam (Reasoning & Knowledge) 8.3%",
        "• LiveCodeBench (Coding) 55%",
        "• SciCode (Coding) 35%",
        "• HumanEval (Coding)",
        "• MATH-500 (Quantitative reasoning) 96%",
        "• AIME 2024 (Competition Math) 81%",
        "Giá trung bình 0.47 USD / 1 triệu token → Dựa trên các thông số giá",
        "• Giá đầu vào 0.4 USD / 1 triệu token.",
        "• Giá đầu ra 0.68 USD / 1 triệu token.",
        "Tốc độ sinh token là 99 token /s.",
        "Độ trễ 0.43s là thời gian chờ trung bình từ khi bấm “enter” gửi thông tin đến khi mô hình trả lời token đầu tiên."
    ],
    contextLengthToken: '131k',
    intelligenceScore: 58,
    pricePerMillionTokens: 0.47,
    speedTokensPerSecond: 99,
    latencyFirstChunkSeconds: 0.43,
  },
  {
    id: 'claude-4-opus',
    name: 'Claude 4 Opus',
    type: 'Mô hình ngôn ngữ lớn',
    developer: 'Anthropic',
    description: `+ Claude 4 Opus là phiên bản cao cấp nhất trong dòng mô hình Claude 4 của Anthropic ( vừa ra mắt tháng 5 năm 2025) Claude Opus 4 được tối ưu đặc biệt cho các tác vụ đòi hỏi khả năng suy luận sâu với nhiều bước phức tạp đi kèm độ chính xác.
+ Claude 4 Opus thật sự có lẽ là mô hình thông minh nhất hiện nay vì các lý do
+ Claude 4 Opus có khả năng suy luận qua nhiều bước (multi-step reasoning), giúp mô hình xử lý vấn đề logic và có hệ thống, giảm tối đa"lối tắt" hay thủ thuật không những thế nó còn bổ sung chế độ  cho phép mô hình tạm dừng để cân nhắc kỹ lưỡng nhiều bước trước khi đưa ra câu trả lời cuối cùng, điều đó giúp nó thông minh hơn 65% so với Claude 3.7 Sonnet.
+ Trong điểm thông minh ở đây không bổ sung benchmark như SWE-bench (78.3%) và Terminal-bench (85.2%) mà Claude 4 Opus đạt được chứ không là nó bỏ xa các mô hình GPT-4.1 (54.6%) và Gemini 2.5 Pro (63.8%).
+ Claude 4 Opus còn rất thân thiện và khả năng hoạt động ổn định với tiếng Việt. Mô hình này là ít lỗi nhất và ổn định nhất so với GPT 4.1 và Gemini 2.5 Pro nếu ai đã từng trải nghiệm nhưng có nhược điểm là giá rất cao vì vậy chỉ phù hợp với những ai có điều kiện và mô hình là doanh nghiệp.`,
    logoUrl: '/image/Logo Claude AI cho bảng xếp hạng.png',
    link: 'https://www.anthropic.com/news/claude-3-family',
    userRating: 4.9,
    ratingCount: 310,
    features: [
        "Độ dài ngữ cảnh (context window) có thể xử lý một lần là 200 nghìn token→ Tức là có thể xử lý khoảng 150 nghìn từ hoặc 600 trang văn bản trong 1 lần xử lý .",
        "Chỉ số thông minh 58 →Dựa trên trung bình các điểm benmark là",
        "• MMLU-Pro (Reasoning & Knowledge) 86%",
        "• GPQA Diamond (Scientific Reasoning) 70%",
        "• Humanity's Last Exam (Reasoning & Knowledge) 5.9%",
        "• LiveCodeBench (Coding) 54%",
        "• SciCode (Coding) 41%",
        "• HumanEval (Coding) 97%",
        "• MATH-500 (Quantitative reasoning) 94%",
        "• AIME 2024 (Competition Math) 56%",
        "Giá trung bình 30 USD / 1 triệu token → Dựa trên các thông số giá",
        "• Giá đầu vào 15.0 USD / 1 triệu token.",
        "• Giá đầu ra 75.0 USD / 1 triệu token.",
        "Tốc độ sinh token là 61.1 token /s.",
        "Độ trễ 2.33s là thời gian chờ trung bình từ khi bấm “enter” gửi thông tin đến khi mô hình trả lời token đầu tiên."
    ],
    isFavorite: false,
    contextLengthToken: '200k',
    intelligenceScore: 58,
    pricePerMillionTokens: 30.00,
    speedTokensPerSecond: 61.1,
    latencyFirstChunkSeconds: 2.33,
  },
  {
    id: 'claude-3.7-sonnet-thinking',
    name: 'Claude 3.7 Sonnet Thinking',
    type: 'Mô hình ngôn ngữ lớn',
    developer: 'Anthropic',
    description: `+ Claude 3.7 Sonnet Thinking ra mắt vào đầu năm 2025, là phiên bản nâng cấp đáng kể so với Claude 3.5 Sonnet, được Anthropic phát triển như một mô hình suy luận lai (hybrid reasoning model) đầu tiên trên thị trường.
+ Claude 3.7 Sonnet không phải là một mô hình riêng biệt cho suy luận mà là sự kết hợp giữa khả năng phản hồi nhanh và suy luận sâu, tương tự cách con người có thể trả lời ngay hoặc dành thời gian suy nghĩ kỹ càng.
+ Khi bật suy luận (thinking), mô hình Claude 3.7 Sonnet Thinking sẽ tự phản tỉnh và thực hiện suy luận đa bước trước khi trả lời, giúp nâng cao hiệu quả trong các lĩnh vực như toán học, vật lý, lập trình, và các tác vụ hướng dẫn phức tạp.
+ Mặc dù là không phải mô hình mới nhất nhưng nó vẫn nổi lên như là giải pháp nằm giữa Claude 4 Opus và Claude 4 Sonnet mà vẫn đảm bảo chi phí phù hợp cho nên nó vẫn hữu dụng trong một số trường hợp khi mà người dùng chắc chắn sẽ chuyển dần sang dòng Claude 4 mới hơn.`,
    logoUrl: '/image/Logo Claude AI cho bảng xếp hạng.png',
    link: 'https://www.anthropic.com/news/claude-3-5-sonnet',
    userRating: 4.9,
    ratingCount: 220,
    features: [
        "Độ dài ngữ cảnh (context window) có thể xử lý một lần là 200 nghìn token → Tức là có thể xử lý khoảng 150 nghìn từ hoặc 600 trang văn bản trong 1 lần xử lý.",
        "Chỉ số thông minh 57 →Dựa trên trung bình các điểm benmark là",
        "• MMLU-Pro (Reasoning & Knowledge) 84%",
        "• GPQA Diamond (Scientific Reasoning) 77%",
        "• Humanity's Last Exam (Reasoning & Knowledge) 10.3%",
        "• LiveCodeBench (Coding) 47%",
        "• SciCode (Coding) 40%",
        "• HumanEval (Coding) 98%",
        "• MATH-500 (Quantitative reasoning) 95%",
        "• AIME 2024 (Competition Math) 49%",
        "Giá trung bình 6 USD / 1 triệu token → Dựa trên các thông số giá",
        "• Giá đầu vào 3.0 USD / 1 triệu token.",
        "• Giá đầu ra 15.0 USD / 1 triệu token.",
        "Tốc độ sinh token là 87.1 token /s.",
        "Độ trễ 1.32s là thời gian chờ trung bình từ khi bấm “enter” gửi thông tin đến khi mô hình trả lời token đầu tiên."
    ],
    contextLengthToken: '200k',
    intelligenceScore: 57,
    pricePerMillionTokens: 6.00,
    speedTokensPerSecond: 87.1,
    latencyFirstChunkSeconds: 1.32,
  },
  {
    id: 'grok-3',
    name: 'Grok 3',
    type: 'Mô hình ngôn ngữ lớn',
    developer: 'xAI',
    description: `+ Grok 3 là phiên bản mô hình AI mới nhất do xAI, công ty của Elon Musk, phát triển và ra mắt chính thức vào tháng 2 năm 2025. Được huấn luyện trên siêu máy tính Colossus với hơn 100.000 GPU Nvidia H100, Grok 3 sở hữu sức mạnh tính toán gấp 10 lần so với các mô hình trước đó của xAI.
+ Grok 3 chính là nền tảng để xAI phát triển Grok 3 Mini Reasoning và hãy nhìn vào sự thể hiện của Grok 3 Mini Reasoning thì thấy Grok 3 thật sự là nền tảng thật sự tuyệt vời.
+ Grok 3 có khả năng truy cập internet và mạng xã hội X (Twitter) để tìm kiếm, xác minh nguồn thông tin và tổng hợp dữ liệu mới nhất trước khi trả lời. Tính năng này giúp mô hình cung cấp các câu trả lời cập nhật, chính xác và phù hợp với bối cảnh thực tế, đây tính năng quan trọng nhất đối với những dự án cần cập nhật tin tức liên tục giúp giữ được độ chính xác.`,
    logoUrl: '/image/Logo Grok cho bảng xếp hạng.png',
    link: 'https://x.ai/grok',
    userRating: 4.4,
    ratingCount: 177,
    features: [
      "Độ dài ngữ cảnh (context window) có thể xử lý 1 lần là 1 triệu token→ Tức là có thể xử lý khoảng 1,5 triệu từ hoặc 5.000 trang văn bản trong 1 lần xử lý.",
      "Chỉ số thông minh 51 →Dựa trên trung bình các điểm benmark là",
      "• MMLU-Pro (Reasoning & Knowledge) 80%",
      "• GPQA Diamond (Scientific Reasoning) 69%",
      "• Humanity's Last Exam (Reasoning & Knowledge) 5.1%",
      "• LiveCodeBench (Coding) 43%",
      "• SciCode (Coding) 37%",
      "• HumanEval (Coding) 91%",
      "• MATH-500 (Quantitative reasoning) 87%",
      "• AIME 2024 (Competition Math) 33%",
      "Giá trung bình 6 USD / 1 triệu token → Dựa trên các thông số giá",
      "• Giá đầu vào 3 USD / 1 triệu token.",
      "• Giá đầu ra 15 USD / 1 triệu token.",
      "Tốc độ sinh token là 92.9 token /s.",
      "Độ trễ 0.47s là thời gian chờ trung bình từ khi bấm “enter” gửi thông tin đến khi mô hình trả lời token đầu tiên."
    ],
    isFavorite: false,
    contextLengthToken: '1m',
    intelligenceScore: 51,
    pricePerMillionTokens: 6.00,
    speedTokensPerSecond: 92.9,
    latencyFirstChunkSeconds: 0.47,
  },
  {
    id: 'llama-4-maverick',
    name: 'Llama 4 Maverick',
    type: 'Mô hình ngôn ngữ lớn',
    developer: 'Meta',
    description: `Llama 4 Maverick là một trong những phiên bản nổi bật nhất thuộc dòng Llama 4 do Meta phát triển, chính thức ra mắt vào tháng 4 năm 2025. Đây là mô hình Al đa phương thức (multimodal) đầu tiên của Meta sử dụng kiến trúc Mixture-of-Experts (MoE) với khả năng xử lý hiệu quả, mạnh mẽ và tiết kiệm tài nguyên. Llama 4 Maverick sở hữu 17 tỷ tham số hoạt động (active parameters) trong tổng số khoảng 400 tỷ tham số, được tổ chức thành 128 chuyên gia (experts). Mỗi token đầu vào được xử lý bởi một chuyên gia riêng biệt cùng với một chuyên gia chung, giúp mô hình chỉ kích hoạt một phần tham số trong quá trình suy luận, từ đó giảm chi phí tính toán và độ trễ khi triển khai. Mô hình có thể chạy hiệu quả trên một máy chủ NVIDIA H100 DGX duy nhất hoặc triển khai phân tán để tối ưu hiệu suất. Llama 4 Maverick được huấn luyện trên dữ liệu đa ngôn ngữ với hơn 200 ngôn ngữ, hỗ trợ tốt 12 ngôn ngữ chính bao gồm tiếng Việt, tiếng Anh, tiếng Pháp, tiếng Đức, tiếng Thái và nhiều ngôn ngữ khác. Mô hình phù hợp với các ứng dụng đa dạng như trợ lý ảo, phân tích hình ảnh, dịch thuật, lập trình, và các hệ thống Al đa nhiệm trong doanh nghiệp.`,
    logoUrl: '/image/Logo LLMA cho bảng xếp hạng.png',
    link: 'https://ai.meta.com/llama/',
    userRating: 4.4,
    ratingCount: 160,
    features: [
      "Độ dài ngữ cảnh (context window) có thể xử lý một lần là 1 triệu token→ Tức là có thể xử lý khoảng 1,5 triệu từ hoặc 5.000 trang văn bản trong 1 lần xử lý.",
      "Chỉ số thông minh 51 →Dựa trên trung bình các điểm benmark là",
      "• MMLU-Pro (Reasoning & Knowledge) 81%",
      "• GPQA Diamond (Scientific Reasoning) 67%",
      "• Humanity's Last Exam (Reasoning & Knowledge) 4.8%",
      "• LiveCodeBench (Coding) 40%",
      "• SciCode (Coding) 33%",
      "• HumanEval (Coding) 88%",
      "• MATH-500 (Quantitative reasoning) 89%",
      "• AIME 2024 (Competition Math) 39%",
      "Giá trung bình 0.39 USD / 1 triệu token → Dựa trên các thông số giá",
      "• Giá đầu vào 0.22 USD / 1 triệu token.",
      "• Giá đầu ra 0.85 USD / 1 triệu token.",
      "Tốc độ sinh token là 164.4 token /s.",
      "Độ trễ 0.33s là thời gian chờ trung bình từ khi bấm “enter” gửi thông tin đến khi mô hình trả lời token đầu tiên."
    ],
    isFavorite: false,
    contextLengthToken: '1m',
    intelligenceScore: 51,
    pricePerMillionTokens: 0.39,
    speedTokensPerSecond: 164.4,
    latencyFirstChunkSeconds: 0.33,
  },
  {
    id: 'grok-3-reasoning-beta',
    name: 'Grok 3 Reasoning Beta',
    type: 'Mô hình ngôn ngữ lớn',
    developer: 'xAI',
    description: `+ Grok 3 Reasoning được thiết kế để thực hiện suy luận theo chuỗi (chain-of-thought reasoning), nghĩa là mô hình sẽ phân tích và giải quyết vấn đề từng bước một cách logic và có hệ thống. Thay vì trả lời ngay lập tức, Grok 3 dành thời gian “suy nghĩ”, thử nghiệm các giả thuyết, phát hiện lỗi và chỉnh sửa trước khi đưa ra kết quả cuối cùng. Điều này giúp tăng độ chính xác và giảm thiểu sai sót trong các bài toán phức tạp.
+ Grok 3 Reasoning vẫn giữ được khả năng truy cập internet và mạng xã hội X (trước đây là Twitter) để tìm kiếm, xác minh nguồn thông tin và tổng hợp dữ liệu mới nhất trước khi trả lời. Tính năng này giúp mô hình cung cấp các câu trả lời cập nhật, chính xác và phù hợp với bối cảnh thực tế, đây tính năng quan trọng nhất đối với những dự án cần cập nhật tin tức liên tục giúp giữ được độ chính xác.
+ Vậy là Grok 3 Reasoning với nền tảng vẫn là Grok 3 nhưng thể hiện thông minh hơn.`,
    logoUrl: '/image/Logo Grok cho bảng xếp hạng.png',
    link: '#',
    userRating: 4.9,
    ratingCount: 120,
    features: [
      "Độ dài ngữ cảnh (context window) có thể xử lý 1 lần là 1 triệu token→ Tức là có thể xử lý khoảng 1,5 triệu từ hoặc 5.000 trang văn bản trong 1 lần xử lý.",
      "Chỉ số thông minh 51 →Dựa trên trung bình các điểm benmark là",
      "• MMLU-Pro (Reasoning & Knowledge)",
      "• GPQA Diamond (Scientific Reasoning) 80%",
      "• Humanity's Last Exam (Reasoning & Knowledge)",
      "• LiveCodeBench (Coding)",
      "• SciCode (Coding)",
      "• HumanEval (Coding)",
      "• MATH-500 (Quantitative reasoning)",
      "• AIME 2024 (Competition Math) 84%",
      "Giá trung bình chưa có thông tin→ Dựa trên các thông số giá",
      "• Giá đầu vào chưa có thông tin.",
      "• Giá đầu ra chưa có thông tin..",
      "Tốc độ sinh token chưa có thông tin.",
      "Độ trễ chưa có thông tin."
    ],
    contextLengthToken: '1m',
    intelligenceScore: 51,
    pricePerMillionTokens: undefined,
    speedTokensPerSecond: undefined,
    latencyFirstChunkSeconds: undefined,
  },
  {
    id: 'qwen3-30b-a3b-reasoning',
    name: 'Qwen3 30B A3B (Reasoning)',
    type: 'Mô hình ngôn ngữ lớn',
    developer: 'Alibaba',
    description: `+ Qwen3 30B A3B là một trong hai phiên bản mô hình Mixture-of-Experts (MoE) tiên tiến thuộc dòng Qwen3 do Alibaba Cloud phát triển, ra mắt đầu năm 2025. Với tổng cộng 30 tỷ tham số nhưng chỉ kích hoạt khoảng 3 tỷ tham số cho mỗi tác vụ, Qwen3 30B A3B tối ưu hóa hiệu quả tính toán trong khi vẫn duy trì khả năng suy luận và xử lý ngôn ngữ vượt trội.
+ Qwen3 30B A3B hỗ trợ hơn 100 ngôn ngữ và phương ngữ, trong đó có tiếng Việt, giúp mô hình dễ dàng ứng dụng trên phạm vi toàn cầu với khả năng giao tiếp tự nhiên và chính xác.
+ Mô hình tích hợp chế độ suy nghĩ (reasoning mode), cho phép thực hiện lập luận từng bước để giải quyết các vấn đề phức tạp như toán học, lập trình và logic đa bước, đồng thời có chế độ không suy nghĩ cho các câu hỏi đơn giản nhằm tối ưu tốc độ phản hồi.
+ Người dùng có thể truy cập miễn phí Qwen3 30B A3B thông qua các API do OpenRouter và Alibaba Cloud cung cấp. Mô hình cũng hỗ trợ tích hợp dễ dàng qua các thư viện phổ biến như Hugging Face Transformers, giúp nhà phát triển nhanh chóng xây dựng và triển khai các ứng dụng Al đa dạng.`,
    logoUrl: '/image/Logo Qwen cho bảng xếp hạng.png',
    link: '#',
    userRating: 4.9,
    ratingCount: 130,
    features: [
        "Độ dài ngữ cảnh (context window) có thể xử lý một lần là 128 nghìn token→ Tức là có thể xử lý khoảng 120 nghìn từ hoặc 400 trang văn bản trong 1 lần xử lý .",
        "Chỉ số thông minh 56 →Dựa trên trung bình các điểm benmark là",
        "• MMLU-Pro (Reasoning & Knowledge) 78%",
        "• GPQA Diamond (Scientific Reasoning) 62%",
        "• Humanity's Last Exam (Reasoning & Knowledge) 6.6%",
        "• LiveCodeBench (Coding) 51%",
        "• SciCode (Coding) 28%",
        "• HumanEval (Coding)",
        "• MATH-500 (Quantitative reasoning) 96%",
        "• AIME 2024 (Competition Math) 75%",
        "Giá trung bình 0.75 USD / 1 triệu token → Dựa trên các thông số giá",
        "• Giá đầu vào 0.2 USD / 1 triệu token.",
        "• Giá đầu ra 2.4 USD / 1 triệu token.",
        "Tốc độ sinh token là 91.7 token /s.",
        "Độ trễ 1.05s là thời gian chờ trung bình từ khi bấm “enter” gửi thông tin đến khi mô hình trả lời token đầu tiên."
    ],
    contextLengthToken: '128k',
    intelligenceScore: 56,
    pricePerMillionTokens: 0.75,
    speedTokensPerSecond: 91.7,
    latencyFirstChunkSeconds: 1.05,
  },
  {
    id: 'claude-4-sonnet-thinking',
    name: 'Claude 4 Sonnet Thinking',
    type: 'Mô hình ngôn ngữ lớn',
    developer: 'Anthropic',
    description: `+ Claude 4 Sonnet Thinking là một trong hai phiên bản chủ lực của dòng mô hình Claude 4 do Anthropic ra mắt vào tháng 5 năm 2025, bên cạnh phiên bản Opus 4. Sonnet 4 được thiết kế để cân bằng giữa hiệu suất và chi phí, phù hợp với các ứng dụng cần khối lượng xử lý lớn, tốc độ phản hồi nhanh nhưng vẫn giữ được khả năng suy luận và lập trình nâng cao.
+ Claude 4 Sonnet Thinking là mô hình mạnh mẽ nhất của Claude 4 Sonnet với chức năng Thinking cho các nhiệm vụ phức tạp, giúp mô hình linh hoạt xử lý từ các câu hỏi nhanh đến các bài toán logic đa bước nhưng vẫn giữ được giá rẻ hơn 20% so với Claude 4 Opus
+ Khi được cấp quyền truy cập file, Sonnet 4 có thể lưu trữ và trích xuất thông tin quan trọng để duy trì ngữ cảnh trong các dự án dài hạn như nghiên cứu hoặc phát triển phần mềm, giúp tăng tính liên tục và hiệu quả trong công việc.`,
    logoUrl: '/image/Logo Claude AI cho bảng xếp hạng.png',
    link: 'https://www.anthropic.com/news/claude-3-family',
    userRating: 4.9,
    ratingCount: 215,
    features: [
      "Độ dài ngữ cảnh (context window) có thể xử lý một lần là 200 nghìn token → Tức là có thể xử lý khoảng 150 nghìn từ hoặc 600 trang văn bản trong 1 lần xử lý.",
      "Chỉ số thông minh 61 →Dựa trên trung bình các điểm benmark là",
      "• MMLU-Pro (Reasoning & Knowledge) 85%",
      "• GPQA Diamond (Scientific Reasoning) 72%",
      "• Humanity's Last Exam (Reasoning & Knowledge) 8.5%",
      "• LiveCodeBench (Coding) 58%",
      "• SciCode (Coding) 40%",
      "• HumanEval (Coding)",
      "• MATH-500 (Quantitative reasoning) 98%",
      "• AIME 2024 (Competition Math) 70%",
      "Giá trung bình 6 USD / 1 triệu token → Dựa trên các thông số giá",
      "• Giá đầu vào 3.0 USD / 1 triệu token.",
      "• Giá đầu ra 15.0 USD / 1 triệu token.",
      "Tốc độ sinh token là 87.1 token /s.",
      "Độ trễ 1.32s là thời gian chờ trung bình từ khi bấm “enter” gửi thông tin đến khi mô hình trả lời token đầu tiên."
    ],
    contextLengthToken: '200k',
    intelligenceScore: 61,
    pricePerMillionTokens: 6.00,
    speedTokensPerSecond: 87.1,
    latencyFirstChunkSeconds: 1.32,
  },
  {
    id: 'claude-4-sonnet',
    name: 'Claude 4 Sonnet',
    type: 'Mô hình ngôn ngữ lớn',
    developer: 'Anthropic',
    description: `+ Claude 4 Sonnet là một trong hai phiên bản chủ lực của dòng mô hình Claude 4 do Anthropic ra mắt
vào tháng 5 năm 2025, bên cạnh phiên bản Opus 4. Sonnet 4 được thiết kế để cân bằng giữa hiệu suất
và chi phí, phù hợp với các ứng dụng cần khối lượng xử lý lớn, tốc độ phản hồi nhanh nhưng vẫn giữ
được khả năng suy luận và lập trình nâng cao.
+ Claude 4 Sonnet là mô hình mạnh mẽ nhất của Claude 4 Sonnet với chức năng
cho các nhiệm vụ phức tạp, giúp mô hình linh hoạt xử lý từ các câu hỏi nhanh đến các bài toán logic đa
bước nhưng vẫn giữ được giá rẻ hơn 20% so với Claude 4 Opus
+ Khi được cấp quyền truy cập file, Sonnet 4 có thể lưu trữ và trích xuất thông tin quan trọng để duy trì
ngữ cảnh trong các dự án dài hạn như nghiên cứu hoặc phát triển phần mềm, giúp tăng tính liên tục và
hiệu quả trong công việc.`,
    logoUrl: '/image/Logo Claude AI cho bảng xếp hạng.png',
    link: 'https://www.anthropic.com/news/claude-3-family',
    userRating: 4.5,
    ratingCount: 240,
    features: [
        "Độ dài ngữ cảnh (context window) có thể xử lý một lần là 200 nghìn token→ Tức là có thể xử lý khoảng 150 nghìn từ hoặc 600 trang văn bản trong 1 lần xử lý .",
        "Chỉ số thông minh 53 →Dựa trên trung bình các điểm benmark là",
        "• MMLU-Pro (Reasoning & Knowledge) 84%",
        "• GPQA Diamond (Scientific Reasoning) 68%",
        "• Humanity's Last Exam (Reasoning & Knowledge) 4%",
        "• LiveCodeBench (Coding) 45%",
        "• SciCode (Coding) 37%",
        "• HumanEval (Coding) 97%",
        "• MATH-500 (Quantitative reasoning) 93%",
        "• AIME 2024 (Competition Math) 41%",
        "Giá trung bình 6 USD / 1 triệu token → Dựa trên các thông số giá",
        "• Giá đầu vào 3.0 USD / 1 triệu token.",
        "• Giá đầu ra 15.0 USD / 1 triệu token.",
        "Tốc độ sinh token là 48.1 token /s.",
        "Độ trễ 1.52s là thời gian chờ trung bình từ khi bấm “enter” gửi thông tin đến khi mô hình trả lời token đầu tiên."
    ],
    isFavorite: false,
    contextLengthToken: '200k',
    intelligenceScore: 53,
    pricePerMillionTokens: 6.00,
    speedTokensPerSecond: 48.1,
    latencyFirstChunkSeconds: 1.52,
  },
  {
    id: 'gpt-4.5-preview',
    name: 'GPT-4.5 (Preview)',
    type: 'Mô hình ngôn ngữ lớn',
    developer: 'OpenAI',
    description: `+ GPT-4.5 là phiên bản nâng cấp của GPT-4 được OpenAl chính thức ra mắt vào cuối tháng 2 năm 2025 dưới dạng bản preview nghiên cứu dành cho người dùng ChatGPT Pro. Đây được xem là “mô hình giàu kiến thức nhất” của OpenAl tính đến thời điểm hiện tại, với nhiều cải tiến về khả năng hiểu ngữ cảnh, tạo sinh văn bản tự nhiên và giảm thiểu hiện tượng ảo giác (hallucination) so với các phiên bản trước.
+ Một trong những vấn đề lớn của các mô hình Al trước đây là tạo ra thông tin sai lệch hoặc không chính xác. GPT-4.5 đã giảm tỷ lệ ảo giác xuống còn khoảng 37%, thấp hơn nhiều so với gần 60% của GPT-4o, giúp tăng độ tin cậy cho người dùng khi sử dụng trong các tác vụ viết lách, lập trình và giải quyết vấn đề thực tế.
+ OpenAl cho biết GPT-4.5 sở hữu “cá tính tinh tế hơn” so với các phiên bản trước, giúp chatbot vận hành trên nền tảng này có cảm giác tự nhiên và dễ tiếp cận hơn, phù hợp với nhiều đối tượng người dùng và mục đích sử dụng khác nhau.
+ Mặc dù có nhiều cải tiến, GPT-4.5 không phải là một bước đột phá về sức mạnh suy luận so với các mô hình nội bộ như o1 hay o3-mini. Thậm chí trong một số trường hợp, khả năng lý luận nhiều bước của GPT-4.5 còn kém hơn o3-mini, có lẽ Open Al vẫn còn đang trong quá trình phát triển GPT4.5`,
    logoUrl: '/image/Logo Open AI cho bảng xếp hạng.png',
    link: 'https://openai.com/',
    userRating: 4.5,
    ratingCount: 190,
    features: [
      "Độ dài ngữ cảnh (context window) có thể xử lý một lần là 128 nghìn token→ Tức là có thể xử lý khoảng 120 nghìn từ hoặc 400 trang văn bản trong 1 lần xử lý.",
      "Chỉ số thông minh 53 →Dựa trên trung bình các điểm benmark là",
      "• MMLU-Pro (Reasoning & Knowledge)",
      "• GPQA Diamond (Scientific Reasoning) 71%",
      "• Humanity's Last Exam (Reasoning & Knowledge)",
      "• LiveCodeBench (Coding)",
      "• SciCode (Coding)",
      "• HumanEval (Coding) 89%",
      "• MATH-500 (Quantitative reasoning)",
      "• AIME 2024 (Competition Math) 37%",
      "Giá trung bình 93.75 USD / 1 triệu token → Dựa trên các thông số giá",
      "• Giá đầu vào 75 USD / 1 triệu token.",
      "• Giá đầu ra 150 USD / 1 triệu token.",
      "Tốc độ sinh token là 76.5 token /s.",
      "Độ trễ 0.94s là thời gian chờ trung bình từ khi bấm “enter” gửi thông tin đến khi mô hình trả lời token đầu tiên."
    ],
    isFavorite: false,
    contextLengthToken: '128k',
    intelligenceScore: 53,
    pricePerMillionTokens: 93.75,
    speedTokensPerSecond: 76.5,
    latencyFirstChunkSeconds: 0.94,
  },
  {
    id: 'gpt-4.1-mini',
    name: 'GPT-4.1 mini',
    type: 'Mô hình ngôn ngữ lớn',
    developer: 'OpenAI',
    description: `GPT-4.1 Mini là biến thể nhỏ gọn của mô hình GPT-4.1 do OpenAl phát triển, ra mắt vào tháng 4 năm 2025. Đây là phiên bản được thiết kế tối ưu cho các ứng dụng cần tốc độ phản hồi nhanh, chi phí thấp nhưng vẫn giữ được hiệu suất và chất lượng cao hơn một chút với GPT-4o.
GPT-4.1 Mini được tối ưu để giảm độ trễ trong quá trình sinh câu trả lời, phù hợp với các ứng dụng tương tác thời gian thực như chatbot, trợ lý ảo, hay các hệ thống tự động hóa quy trình công việc.
Mặc dù là phiên bản nhỏ hơn, GPT-4.1 Mini vẫn kế thừa khả năng xử lý ngữ cảnh dài lên đến 1 triệu token, giúp mô hình duy trì hiệu quả trong các tác vụ phân tích tài liệu lớn, lập trình phức tạp và các ứng dụng đòi hỏi lưu giữ thông tin dài hạn.`,
    logoUrl: '/image/Logo Open AI cho bảng xếp hạng.png',
    link: 'https://openai.com/',
    userRating: 4.5,
    ratingCount: 225,
    features: [
        "Độ dài ngữ cảnh (context window) có thể xử lý một lần là 1 triệu token→ Tức là có thể xử lý khoảng 1,5 triệu từ hoặc 5.000 trang văn bản trong 1 lần xử lý.",
        "Chỉ số thông minh 53 → Dựa trên trung bình các điểm benmark là",
        "• MMLU-Pro (Reasoning & Knowledge) 78%",
        "• GPQA Diamond (Scientific Reasoning) 66%",
        "• Humanity's Last Exam (Reasoning & Knowledge) 4.6%",
        "• LiveCodeBench (Coding) 48%",
        "• SciCode (Coding) 40%",
        "• HumanEval (Coding) 95%",
        "• MATH-500 (Quantitative reasoning) 93%",
        "• AIME 2024 (Competition Math) 43%",
        "Giá trung bình 0.7 USD / 1 triệu token → Dựa trên các thông số giá",
        "• Giá đầu vào 0.4 USD / 1 triệu token.",
        "• Giá đầu ra 1.6 USD / 1 triệu token.",
        "Tốc độ sinh token là 66.8 token /s.",
        "Độ trễ 0.5s là thời gian chờ trung bình từ khi bấm “enter” gửi thông tin đến khi mô hình trả lời token đầu tiên."
    ],
    isFavorite: false,
    contextLengthToken: '1m',
    intelligenceScore: 53,
    pricePerMillionTokens: 0.7,
    speedTokensPerSecond: 66.8,
    latencyFirstChunkSeconds: 0.5,
  },
  {
    id: 'gpt-4.1',
    name: 'GPT-4.1',
    type: 'Mô hình ngôn ngữ lớn',
    developer: 'OpenAI',
    description: `GPT-4.1 là mô hình Al thế hệ mới được OpenAl ra mắt vào tháng 4 năm 2025, đánh dấu bước tiến vượt bậc so với phiên bản GPT-4o trước đó. Với nhiều cải tiến về khả năng lập trình, hiểu ngữ cảnh dài và tuân thủ hướng dẫn, GPT-4.1 mang đến hiệu suất vượt trội cùng chi phí sử dụng giảm đến 26%, phù hợp cho cả doanh nghiệp và nhà phát triển cá nhân.
GPT-4.1 thể hiện khả năng lập trình tốt hơn 21% so với GPT-4o và 27% so với GPT-4.5 trong các bài kiểm tra nội bộ của OpenAI. Mô hình cũng cải thiện khả năng tuân theo hướng dẫn và xử lý ngữ cảnh dài, giúp vận hành các tác tử Al hiệu quả hơn.
GPT-4.1 có thể xử lý lên đến 1 triệu token trong một lần truy vấn, gấp tám lần giới hạn 128.000 token của GPT-4o.
So với GPT-4o, GPT-4.1 giảm 26% chi phí API, giúp tiết kiệm đáng kể cho các doanh nghiệp và nhà phát triển khi triển khai các ứng dụng Al quy mô lớn.`,
    logoUrl: '/image/Logo Open AI cho bảng xếp hạng.png',
    link: 'https://openai.com/',
    userRating: 4.5,
    ratingCount: 260,
    features: [
        "Độ dài ngữ cảnh (context window) có thể xử lý một lần là 1 triệu token→ Tức là có thể xử lý khoảng 1,5 triệu từ hoặc 5.000 trang văn bản trong 1 lần xử lý.",
        "Chỉ số thông minh 53 →Dựa trên trung bình các điểm benmark là",
        "• MMLU-Pro (Reasoning & Knowledge) 81%",
        "• GPQA Diamond (Scientific Reasoning) 67%",
        "• Humanity's Last Exam (Reasoning & Knowledge) 4.6%",
        "• LiveCodeBench (Coding) 46%",
        "• SciCode (Coding) 38%",
        "• HumanEval (Coding) 96%",
        "• MATH-500 (Quantitative reasoning) 91%",
        "• AIME 2024 (Competition Math) 44%",
        "Giá trung bình 3.5 USD / 1 triệu token → Dựa trên các thông số giá",
        "• Giá đầu vào 2 USD / 1 triệu token.",
        "• Giá đầu ra 8 USD / 1 triệu token.",
        "Tốc độ sinh token là 97.2 token/s.",
        "Độ trễ 0.54s là thời gian chờ trung bình từ khi bấm “enter” gửi thông tin đến khi mô hình trả lời token đầu tiên."
    ],
    isFavorite: false,
    contextLengthToken: '1m',
    intelligenceScore: 53,
    pricePerMillionTokens: 3.5,
    speedTokensPerSecond: 97.2,
    latencyFirstChunkSeconds: 0.54,
  },
  {
    id: 'deepseek-r1-jan25',
    name: 'DeepSeek R1 0528',
    type: 'Mô hình ngôn ngữ lớn',
    developer: 'Deepseek',
    description: `+ DeepSeek R1-0528 là phiên bản nâng cấp mới nhất DeepSeek, được công bố vào tháng 5 năm 2025 và cũng là mô hình mã nguồn mở nên người dùng có thể triển khai cục bộ trên chính máy chủ của các bạn.
+ Phiên bản này đánh dấu bước tiến quan trọng trong khả năng suy luận sâu sắc, hiệu suất xử lý và tối ưu tài nguyên, giúp DeepSeek R1 có thể cạnh tranh trực tiếp cả về chất lượng và giá cả với các mô hình của Google và Open Al.
+ Không giống các mô hình "open-weight" nhưng hạn chế giấy phép (như LLaMA), DeepSeek R1 cho phép sử dụng thương mại, tùy chỉnh và triển khai tự do, khiến nó trở thành “trụ cột" mới cho các startup, nhà nghiên cứu, và ứng dụng Al độc lập.
+ Đổi lại là tốc độ sinh token khá chậm 28.6 token/s cho nên người dùng sẽ chờ đợi hơi lâu nhưng đó không là gì so với tiềm năng nó mang lại.`,
    logoUrl: '/image/Logo Deepseek cho bảng xếp hạng.png',
    link: 'https://www.deepseek.com/',
    userRating: 4.9,
    ratingCount: 155,
    features: [
        "Độ dài ngữ cảnh (context window) có thể xử lý một lần là 128 nghìn token → Tức là có thể xử lý khoảng 120 nghìn từ hoặc 400 trang văn bản trong 1 lần xử lý.",
        "Chỉ số thông minh 68 →Dựa trên trung bình các điểm benmark là",
        "• MMLU-Pro (Reasoning & Knowledge) 85%",
        "• GPQA Diamond (Scientific Reasoning) 81%",
        "• Humanity's Last Exam (Reasoning & Knowledge) 14.9%",
        "• LiveCodeBench (Coding) 77%",
        "• SciCode (Coding) 40%",
        "• HumanEval (Coding) 97%",
        "• MATH-500 (Quantitative reasoning) 98%",
        "• AIME 2024 (Competition Math) 89%",
        "Giá trung bình 0.96 USD / 1 triệu token → Dựa trên các thông số giá",
        "• Giá đầu vào 0.55 USD / 1 triệu token.",
        "• Giá đầu ra 2.19 USD / 1 triệu token.",
        "Tốc độ sinh token là 28.6 token /s.",
        "Độ trễ 2.49s là thời gian chờ trung bình từ khi bấm “enter” gửi thông tin đến khi mô hình trả lời token đầu tiên."
    ],
    contextLengthToken: '128k',
    intelligenceScore: 68,
    pricePerMillionTokens: 0.96,
    speedTokensPerSecond: 28.6,
    latencyFirstChunkSeconds: 2.49,
  },
  {
    id: 'openai-o3',
    name: 'Open AI o3',
    type: 'Mô hình ngôn ngữ lớn',
    developer: 'OpenAI',
    description: `+ OpenAI o3 là mô hình ngôn ngữ thế hệ mới do OpenAI phát triển, được ra mắt chính thức vào cuối năm 2024 như một bước tiến vượt bậc so với phiên bản tiền nhiệm o1. Đây là một mô hình transformer phản chiếu (reflective generative pre-trained transformer) được thiết kế đặc biệt để xử lý các câu hỏi đòi hỏi suy luận logic nhiều bước và tư duy phân tích sâu sắc
+ OpenAI o3 là một trong những mô hình đầu tiên của OpenAI có khả năng sử dụng công cụ một cách tự động trong quy trình suy luận, từ đó có thể truy cập thông tin thời gian thực, phân tích dữ liệu phức tạp và phối hợp nhiều khả năng để giải quyết các vấn đề đa bước hiệu quả hơn.
+ OpenAI o3 đã áp dụng các kỹ thuật điều chỉnh và kiểm soát mới nhằm giảm thiểu các kết quả gây hại hoặc thiên lệch, đồng thời nâng cao tính minh bạch trong quá trình suy luận của mô hình.
+ Mô hình cũng được tích hợp trong các dịch vụ như ChatGPT, API, Playground`,
    logoUrl: '/image/Logo Open AI cho bảng xếp hạng.png',
    link: 'https://openai.com/',
    userRating: 4.9,
    ratingCount: 350,
    features: [
      "Độ dài ngữ cảnh (context window) có thể xử lý một lần là 200 nghìn token→ Tức là có thể xử lý khoảng 150 nghìn từ hoặc 600 trang văn bản trong 1 lần xử lý .",
      "Chỉ số thông minh 70 →Dựa trên trung bình các điểm benmark là",
      "• MMLU-Pro (Reasoning & Knowledge) 85%",
      "• GPQA Diamond (Scientific Reasoning) 83%",
      "• Humanity's Last Exam (Reasoning & Knowledge) 20%",
      "• LiveCodeBench (Coding) 78%",
      "• SciCode (Coding) 41%",
      "• HumanEval (Coding) 99%",
      "• MATH-500 (Quantitative reasoning) 99%",
      "• AIME 2024 (Competition Math) 90%",
      "Giá trung bình 3.5 USD / 1 triệu token → Dựa trên các thông số giá",
      "• Giá đầu vào 2.0 USD / 1 triệu token.",
      "• Giá đầu ra 8.0 USD / 1 triệu token.",
      "Tốc độ sinh token là 110.4 token /s.",
      "Độ trễ 22.23s là thời gian chờ trung bình từ khi bấm “enter” gửi thông tin đến khi mô hình trả lời token đầu tiên."
    ],
    isFavorite: false,
    contextLengthToken: '200k',
    intelligenceScore: 70,
    pricePerMillionTokens: 3.5,
    speedTokensPerSecond: 110.4,
    latencyFirstChunkSeconds: 22.23,
  },
  {
    id: 'llama-nemotron-ultra-reasoning',
    name: 'Llama Nemotron Ultra Reasoning',
    type: 'Mô hình ngôn ngữ lớn',
    developer: 'Nvidia',
    description: `+ Llama Nemotron Ultra là phiên bản cao cấp nhất trong dòng mô hình Llama Nemotron do NVIDIA phát triển, dựa trên nền tảng Llama 3.1 của Meta, với quy mô 253 tỷ tham số. Ra mắt đầu năm 2025, Nemotron Ultra được thiết kế đặc biệt để xử lý các tác vụ suy luận phức tạp, toán học nâng cao, lập trình và các nhiệm vụ khoa học với độ chính xác và hiệu suất vượt trội.
+ Mô hình được tối ưu đặc biệt cho hạ tầng GPU NVIDIA đa thiết bị, sử dụng các kỹ thuật như Neural Architecture Search (NAS) và Feed-Forward Network (FFN) Fusion giúp giảm đáng kể độ trễ và tăng thông lượng, đồng thời tiết kiệm bộ nhớ và chi phí vận hành trong môi trường trung tâm dữ liệu. Vì vậy cực kì thích hợp cho những cá nhân, công ty đang chạy phần cứng của Nvidia.
+ NVIDIA phát hành Llama Nemotron Ultra dưới giấy phép mở, cho phép doanh nghiệp và nhà phát triển sử dụng, tùy chỉnh và triển khai mô hình trong các ứng dụng thương mại với độ tin cậy cao.`,
    logoUrl: '/image/Logo Llama Nemotron Ultra Reasoning cho bảng xếp hạng.png',
    link: '#',
    userRating: 4.9,
    ratingCount: 188,
    features: [
      "Độ dài ngữ cảnh (context window) có thể xử lý một lần là 128 nghìn token → Tức là có thể xử lý khoảng 120 nghìn từ hoặc 400 trang văn bản trong 1 lần xử lý.",
      "Chỉ số thông minh 61 →Dựa trên trung bình các điểm benmark là",
      "• MMLU-Pro (Reasoning & Knowledge) 83%",
      "• GPQA Diamond (Scientific Reasoning) 73%",
      "• Humanity's Last Exam (Reasoning & Knowledge) 8.1%",
      "• LiveCodeBench (Coding) 64%",
      "• SciCode (Coding) 35%",
      "• HumanEval (Coding)",
      "• MATH-500 (Quantitative reasoning) 95%",
      "• AIME 2024 (Competition Math) 75%",
      "Giá trung bình 0.9 USD / 1 triệu token → Dựa trên các thông số giá",
      "• Giá đầu vào 0.6 USD / 1 triệu token.",
      "• Giá đầu ra 1.8 USD / 1 triệu token.",
      "Tốc độ sinh token là 42.7 token /s.",
      "Độ trễ 0.66s là thời gian chờ trung bình từ khi bấm “enter” gửi thông tin đến khi mô hình trả lời token đầu tiên."
    ],
    contextLengthToken: '128k',
    intelligenceScore: 61,
    pricePerMillionTokens: 0.90,
    speedTokensPerSecond: 42.7,
    latencyFirstChunkSeconds: 0.66,
  },
];

export const mockNews: NewsArticle[] = [
  {
    id: 'chatgpt-free-mobile',
    title: 'Tất cả các tính năng ChatGPT miễn phí có thể sẽ có trên điện thoại di động',
    source: 'Tinhte.vn',
    content: `Theo các nguồn tin đáng tin cậy, OpenAI đang chuẩn bị đưa tất cả các tính năng miễn phí của ChatGPT lên các ứng dụng di động của mình. Điều này bao gồm khả năng truy cập vào mô hình GPT-4o, tải lên tệp và hình ảnh, sử dụng các công cụ tìm kiếm, phân tích dữ liệu và khám phá các GPT tùy chỉnh.

Hiện tại, các tính năng này chỉ có sẵn cho người dùng trả phí trên di động hoặc người dùng miễn phí trên phiên bản web. Việc mở rộng này sẽ mang lại trải nghiệm nhất quán hơn cho tất cả người dùng, bất kể họ sử dụng ChatGPT trên nền tảng nào.

[IMAGE:https://placehold.co/750x420.png|Một tòa nhà văn phòng hiện đại|office building]

Động thái này diễn ra trong bối cảnh cạnh tranh ngày càng gay gắt trong lĩnh vực AI. Google gần đây đã công bố các tính năng AI mới trong tìm kiếm và Microsoft cũng đang tích hợp Copilot sâu hơn vào các sản phẩm của mình. Bằng cách cung cấp các tính năng mạnh mẽ miễn phí trên di động, OpenAI hy vọng sẽ thu hút thêm nhiều người dùng và củng cố vị trí dẫn đầu của mình trên thị trường.

Việc này cũng được cho là một bước đi để chuẩn bị cho việc tích hợp ChatGPT vào các hệ điều hành di động trong tương lai, khi Apple được đồn đoán sẽ công bố quan hệ đối tác với OpenAI tại sự kiện WWDC sắp tới.

[IMAGE:https://placehold.co/750x420.png|Một không gian làm việc văn phòng hợp tác|office interior]

Người dùng di động sẽ sớm có thể tận hưởng các tính năng như:
- **Phân tích biểu đồ và bảng biểu:** Tải lên và đặt câu hỏi về dữ liệu của bạn.
- **Hỏi về hình ảnh:** Chụp ảnh và nhận câu trả lời liên quan.
- **Tải lên tệp:** Nhận bản tóm tắt hoặc câu trả lời từ tài liệu PDF và các tệp khác.

Mặc dù chưa có thông báo chính thức từ OpenAI, các dấu hiệu trong mã nguồn ứng dụng cho thấy việc triển khai có thể diễn ra trong vài tuần tới.`,
    publishedAt: '2025-05-12T08:00:00Z',
    imageUrl: 'https://placehold.co/800x450.png',
    link: '#',
    dataAiHint: 'phone chat'
  },
  {
    id: 'news1',
    title: 'Claude 3 Opus Giành Vị trí Dẫn đầu trong Đấu trường AI, Vượt qua GPT-4',
    source: 'Anthropic',
    content: 'Mô hình mới nhất của Anthropic, Claude 3 Opus, đã chứng minh hiệu suất vượt trội trong các bài kiểm tra khác nhau, có khả năng vượt qua GPT-4 của OpenAI trong các lĩnh vực quan trọng về lý luận và kiến thức.',
    publishedAt: '2025-06-08T10:00:00Z',
    imageUrl: 'https://placehold.co/400x225.png',
    link: '#',
    dataAiHint: 'AI model'
  },
  {
    id: 'news2',
    title: 'Tương lai của AI trong Chăm sóc Sức khỏe: Dự đoán cho năm 2025',
    source: 'Tech Journal',
    content: 'Các chuyên gia dự đoán AI sẽ cách mạng hóa chẩn đoán, y học cá nhân hóa và khám phá thuốc trong vài năm tới, dẫn đến việc chăm sóc sức khỏe hiệu quả hơn.',
    publishedAt: '2025-06-07T14:30:00Z',
    imageUrl: 'https://placehold.co/400x225.png',
    link: '#',
    dataAiHint: 'AI healthcare'
  },
  {
    id: 'news3',
    title: 'AI Đạo đức: Điều hướng các Thách thức về Thiên vị và Minh bạch',
    source: 'AI Ethics Weekly',
    content: 'Khi các hệ thống AI ngày càng được tích hợp vào xã hội, việc giải quyết các vấn đề về thiên vị, công bằng và minh bạch là rất quan trọng để phát triển và triển khai có trách nhiệm.',
    publishedAt: '2025-06-06T09:15:00Z',
    imageUrl: 'https://placehold.co/400x225.png',
    link: '#',
    dataAiHint: 'AI ethics'
  },
];
